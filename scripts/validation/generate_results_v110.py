"""
ç”Ÿæˆv1.1.0ç‰ˆæœ¬çš„ç»“æœç›®å½•ç»“æ„å’Œè¯„ä¼°æŠ¥å‘Š
ç±»ä¼¼äºv1.0.3çš„ç»“æ„
"""

import os
import sys
import json
import shutil
from pathlib import Path
from typing import Dict, List, Optional
import numpy as np
import cv2
from datetime import datetime
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.patches as patches

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from sider_captcha_solver.predictor import CaptchaPredictor


class ResultsGeneratorV110:
    """v1.1.0ç»“æœç”Ÿæˆå™¨"""
    
    def __init__(self, model_path: str = "src/checkpoints/1.1.0/best_model.pth"):
        """
        åˆå§‹åŒ–ç»“æœç”Ÿæˆå™¨
        
        Args:
            model_path: æ¨¡å‹è·¯å¾„
        """
        self.model_path = Path(model_path)
        self.results_dir = Path("results/1.1.0")
        
        # åˆ›å»ºç›®å½•ç»“æ„
        self.real_captchas_dir = self.results_dir / "real_captchas"
        self.test_dataset_dir = self.results_dir / "test_dataset"
        
        # åˆ›å»ºå¯è§†åŒ–å­ç›®å½•
        self.real_vis_dir = self.real_captchas_dir / "visualizations"
        self.test_vis_dir = self.test_dataset_dir / "visualizations"
        
        # åˆ›å»ºæ‰€æœ‰ç›®å½•
        for dir_path in [self.real_vis_dir, self.test_vis_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        print(f"âœ… Created directory structure at: {self.results_dir}")
        
        # åŠ è½½æ¨¡å‹
        self.predictor = None
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½æ¨¡å‹"""
        try:
            self.predictor = CaptchaPredictor(
                model_path=str(self.model_path),
                device='auto'
            )
            print(f"âœ… Model loaded: {self.model_path}")
        except Exception as e:
            print(f"âŒ Failed to load model: {e}")
            raise
    
    def evaluate_real_captchas(self):
        """è¯„ä¼°çœŸå®éªŒè¯ç æ•°æ®é›†"""
        print("\nğŸ“Š Evaluating real CAPTCHAs...")
        
        # æ•°æ®ç›®å½•
        data_dir = Path("data/real_captchas/annotated")
        if not data_dir.exists():
            print(f"âŒ Directory not found: {data_dir}")
            return
        
        # è·å–æ‰€æœ‰å›¾ç‰‡
        image_files = sorted(data_dir.glob("*.png"))[:100]  # é™åˆ¶å‰100å¼ 
        
        results = {
            "model_version": "1.1.0",
            "dataset": "real_captchas",
            "timestamp": datetime.now().isoformat(),
            "total_images": len(image_files),
            "predictions": [],
            "metrics": {}
        }
        
        errors = []
        processing_times = []
        
        # è¯„ä¼°æ¯å¼ å›¾ç‰‡
        for idx, img_path in enumerate(tqdm(image_files, desc="Processing")):
            try:
                # è§£ææ–‡ä»¶åè·å–çœŸå®åæ ‡
                # æ ¼å¼: Pic0001_Bgx112Bgy97_Sdx32Sdy98_hash.png
                import re
                pattern = r"Pic(\d+)_Bgx(\d+)Bgy(\d+)_Sdx(\d+)Sdy(\d+)_(\w+)\.png"
                match = re.match(pattern, img_path.name)
                
                if not match:
                    continue
                
                _, gap_x_true, gap_y_true, slider_x_true, slider_y_true, _ = match.groups()
                gap_x_true = int(gap_x_true)
                gap_y_true = int(gap_y_true)
                slider_x_true = int(slider_x_true)
                slider_y_true = int(slider_y_true)
                
                # é¢„æµ‹
                pred = self.predictor.predict(str(img_path))
                
                if pred['success']:
                    # è®¡ç®—è¯¯å·®
                    gap_error = np.sqrt((pred['gap_x'] - gap_x_true)**2 + 
                                      (pred['gap_y'] - gap_y_true)**2)
                    slider_error = np.sqrt((pred['slider_x'] - slider_x_true)**2 + 
                                         (pred['slider_y'] - slider_y_true)**2)
                    distance_error = abs(pred['sliding_distance'] - (gap_x_true - slider_x_true))
                    
                    # è®°å½•ç»“æœ
                    prediction = {
                        "image": img_path.name,
                        "ground_truth": {
                            "gap_x": gap_x_true,
                            "gap_y": gap_y_true,
                            "slider_x": slider_x_true,
                            "slider_y": slider_y_true,
                            "sliding_distance": gap_x_true - slider_x_true
                        },
                        "prediction": {
                            "gap_x": pred['gap_x'],
                            "gap_y": pred['gap_y'],
                            "slider_x": pred['slider_x'],
                            "slider_y": pred['slider_y'],
                            "sliding_distance": pred['sliding_distance'],
                            "confidence": pred['confidence']
                        },
                        "errors": {
                            "gap_error": gap_error,
                            "slider_error": slider_error,
                            "distance_error": distance_error
                        },
                        "processing_time_ms": pred['processing_time_ms']
                    }
                    
                    results["predictions"].append(prediction)
                    errors.append(distance_error)
                    processing_times.append(pred['processing_time_ms'])
                    
                    # ç”Ÿæˆå¯è§†åŒ–ï¼ˆæ¯å¼ éƒ½ä¿å­˜ï¼Œæœ€å¤š100å¼ ï¼‰
                    if idx < 100:  # ä¿å­˜å‰100å¼ çš„å¯è§†åŒ–
                        self._visualize_prediction(
                            img_path, pred, 
                            self.real_vis_dir / f"sample_{idx:04d}.png",
                            gt_gap_x=gap_x_true,
                            gt_gap_y=gap_y_true,
                            gt_slider_x=slider_x_true,
                            gt_slider_y=slider_y_true
                        )
            
            except Exception as e:
                print(f"Error processing {img_path.name}: {e}")
                continue
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        if errors:
            errors = np.array(errors)
            results["metrics"] = {
                "mae": float(np.mean(errors)),
                "median_error": float(np.median(errors)),
                "max_error": float(np.max(errors)),
                "hit_le_2px": float(np.mean(errors <= 2) * 100),
                "hit_le_3px": float(np.mean(errors <= 3) * 100),
                "hit_le_5px": float(np.mean(errors <= 5) * 100),
                "hit_le_10px": float(np.mean(errors <= 10) * 100),
                "avg_processing_time_ms": float(np.mean(processing_times)),
                "success_rate": float(len(results["predictions"]) / len(image_files) * 100)
            }
        
        # ä¿å­˜ç»“æœ
        output_path = self.real_captchas_dir / "evaluation_results.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Real CAPTCHA results saved to: {output_path}")
        print(f"   - MAE: {results['metrics'].get('mae', 0):.2f} px")
        print(f"   - 5px Accuracy: {results['metrics'].get('hit_le_5px', 0):.1f}%")
        
        return results
    
    def evaluate_test_dataset(self):
        """è¯„ä¼°æµ‹è¯•æ•°æ®é›†"""
        print("\nğŸ“Š Evaluating test dataset...")
        
        # æ•°æ®ç›®å½•
        data_dir = Path("data/captchas")
        if not data_dir.exists():
            print(f"âŒ Directory not found: {data_dir}")
            return
        
        # è·å–æµ‹è¯•å›¾ç‰‡
        image_files = sorted(data_dir.glob("*.png"))[:1000]  # é™åˆ¶å‰1000å¼ 
        
        results = {
            "model_version": "1.1.0",
            "dataset": "test_dataset",
            "timestamp": datetime.now().isoformat(),
            "total_images": len(image_files),
            "predictions": [],
            "metrics": {}
        }
        
        errors = []
        processing_times = []
        
        # è¯„ä¼°æ¯å¼ å›¾ç‰‡ï¼ˆå¤„ç†å‰100å¼ ï¼‰
        for idx, img_path in enumerate(tqdm(image_files[:100], desc="Processing")):
            try:
                # è§£ææ–‡ä»¶å
                import re
                pattern = r"Pic(\d+)_Bgx(\d+)Bgy(\d+)_Sdx(\d+)Sdy(\d+)_(\w+)\.png"
                match = re.match(pattern, img_path.name)
                
                if not match:
                    continue
                
                _, gap_x_true, gap_y_true, slider_x_true, slider_y_true, _ = match.groups()
                gap_x_true = int(gap_x_true)
                gap_y_true = int(gap_y_true)
                slider_x_true = int(slider_x_true)
                slider_y_true = int(slider_y_true)
                
                # é¢„æµ‹
                pred = self.predictor.predict(str(img_path))
                
                if pred['success']:
                    # è®¡ç®—è¯¯å·®
                    distance_error = abs(pred['sliding_distance'] - (gap_x_true - slider_x_true))
                    
                    # è®°å½•ç®€åŒ–ç»“æœ
                    prediction = {
                        "image": img_path.name,
                        "distance_error": distance_error,
                        "processing_time_ms": pred['processing_time_ms']
                    }
                    
                    results["predictions"].append(prediction)
                    errors.append(distance_error)
                    processing_times.append(pred['processing_time_ms'])
                    
                    # ç”Ÿæˆå¯è§†åŒ–ï¼ˆæ¯å¼ éƒ½ä¿å­˜ï¼Œæœ€å¤š100å¼ ï¼‰
                    if idx < 100:
                        self._visualize_prediction(
                            img_path, pred,
                            self.test_vis_dir / f"sample_{idx:04d}.png",
                            gt_gap_x=gap_x_true,
                            gt_gap_y=gap_y_true,
                            gt_slider_x=slider_x_true,
                            gt_slider_y=slider_y_true
                        )
            
            except Exception as e:
                continue
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        if errors:
            errors = np.array(errors)
            results["metrics"] = {
                "mae": float(np.mean(errors)),
                "median_error": float(np.median(errors)),
                "max_error": float(np.max(errors)),
                "hit_le_2px": float(np.mean(errors <= 2) * 100),
                "hit_le_3px": float(np.mean(errors <= 3) * 100),
                "hit_le_5px": float(np.mean(errors <= 5) * 100),
                "hit_le_10px": float(np.mean(errors <= 10) * 100),
                "avg_processing_time_ms": float(np.mean(processing_times))
            }
        
        # ä¿å­˜ç»“æœ
        output_path = self.test_dataset_dir / "evaluation_results.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Test dataset results saved to: {output_path}")
        print(f"   - MAE: {results['metrics'].get('mae', 0):.2f} px")
        print(f"   - 5px Accuracy: {results['metrics'].get('hit_le_5px', 0):.1f}%")
        
        return results
    
    def _visualize_prediction(self, img_path: Path, prediction: Dict, output_path: Path, 
                              gt_gap_x: int = None, gt_gap_y: int = None,
                              gt_slider_x: int = None, gt_slider_y: int = None):
        """ç”Ÿæˆé¢„æµ‹å¯è§†åŒ– - åŒ…å«GTå’ŒPredçš„å¯¹æ¯”"""
        try:
            # è¯»å–å›¾ç‰‡
            image = cv2.imread(str(img_path))
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # åˆ›å»ºå›¾å½¢
            fig, ax = plt.subplots(1, 1, figsize=(10, 5))
            ax.imshow(image)
            
            # æå–é¢„æµ‹åæ ‡
            pred_gap_x = prediction['gap_x']
            pred_gap_y = prediction['gap_y']
            pred_slider_x = prediction['slider_x']
            pred_slider_y = prediction['slider_y']
            
            # æ ‡æ³¨å¤§å°è®¾ç½®
            circle_size = 5  # åœ†åœˆåŠå¾„ï¼ˆå†ç¼©å°ä¸€åŠï¼‰
            text_offset = 10  # æ–‡å­—åç§»
            
            # å¦‚æœæä¾›äº†GTåæ ‡ï¼Œç»˜åˆ¶GTæ ‡æ³¨ï¼ˆå®å¿ƒç»¿è‰²ï¼‰
            if gt_gap_x is not None and gt_gap_y is not None:
                # GT Gap - å®å¿ƒç»¿è‰²åœ†åœˆ
                gt_gap_circle = patches.Circle((gt_gap_x, gt_gap_y), circle_size, 
                                              linewidth=2, edgecolor='green', 
                                              facecolor='green', alpha=0.3)
                ax.add_patch(gt_gap_circle)
                ax.text(gt_gap_x, gt_gap_y - text_offset, 'GT Gap', 
                       color='green', fontsize=10, fontweight='bold',
                       ha='center', va='bottom')
            
            if gt_slider_x is not None and gt_slider_y is not None:
                # GT Slider - å®å¿ƒç»¿è‰²åœ†åœˆ
                gt_slider_circle = patches.Circle((gt_slider_x, gt_slider_y), circle_size,
                                                 linewidth=2, edgecolor='green',
                                                 facecolor='green', alpha=0.3)
                ax.add_patch(gt_slider_circle)
                ax.text(gt_slider_x, gt_slider_y - text_offset, 'GT Slider',
                       color='green', fontsize=10, fontweight='bold',
                       ha='center', va='bottom')
            
            # ç»˜åˆ¶é¢„æµ‹ç»“æœ
            # Pred Gap - çº¢è‰²è™šçº¿ç©ºå¿ƒåœ†åœˆ
            pred_gap_circle = patches.Circle((pred_gap_x, pred_gap_y), circle_size, 
                                            linewidth=2, edgecolor='red', 
                                            facecolor='none', linestyle='--')
            ax.add_patch(pred_gap_circle)
            ax.text(pred_gap_x, pred_gap_y + text_offset, 'Pred Gap',
                   color='red', fontsize=10, fontweight='bold',
                   ha='center', va='top')
            
            # Pred Slider - è“è‰²è™šçº¿ç©ºå¿ƒåœ†åœˆ
            pred_slider_circle = patches.Circle((pred_slider_x, pred_slider_y), circle_size,
                                               linewidth=2, edgecolor='blue',
                                               facecolor='none', linestyle='--')
            ax.add_patch(pred_slider_circle)
            ax.text(pred_slider_x, pred_slider_y + text_offset, 'Pred Slider',
                   color='blue', fontsize=10, fontweight='bold',
                   ha='center', va='top')
            
            # ä¸ç»˜åˆ¶ç®­å¤´
            
            # è®¡ç®—è¯¯å·®
            distance = prediction['sliding_distance']
            confidence = prediction['confidence']
            
            # å¦‚æœæœ‰GTï¼Œè®¡ç®—è¯¯å·®
            if gt_gap_x is not None and gt_slider_x is not None:
                gt_distance = gt_gap_x - gt_slider_x
                error = abs(distance - gt_distance)
                title = f"Pred Distance: {distance:.1f}px | GT Distance: {gt_distance}px | Error: {error:.1f}px | Conf: {confidence:.3f}"
            else:
                title = f"Distance: {distance:.1f}px | Confidence: {confidence:.3f}"
            
            ax.set_title(title, fontsize=11)
            ax.axis('off')
            
            # ä¿å­˜
            plt.savefig(output_path, dpi=120, bbox_inches='tight')
            plt.close()
            
        except Exception as e:
            print(f"Visualization error: {e}")
    
    def generate_summary_report(self, real_results: Dict, test_results: Dict):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        summary = {
            "model_version": "1.1.0",
            "timestamp": datetime.now().isoformat(),
            "real_captchas": {
                "total_evaluated": real_results.get("total_images", 0),
                "metrics": real_results.get("metrics", {})
            },
            "test_dataset": {
                "total_evaluated": test_results.get("total_images", 0),
                "metrics": test_results.get("metrics", {})
            },
            "comparison": {
                "real_vs_test_mae_diff": abs(
                    real_results.get("metrics", {}).get("mae", 0) - 
                    test_results.get("metrics", {}).get("mae", 0)
                ),
                "real_vs_test_5px_diff": abs(
                    real_results.get("metrics", {}).get("hit_le_5px", 0) - 
                    test_results.get("metrics", {}).get("hit_le_5px", 0)
                )
            },
            "model_info": {
                "checkpoint": str(self.model_path),
                "device": str(self.predictor.device) if self.predictor else "unknown"
            }
        }
        
        # ä¿å­˜æ€»ç»“æŠ¥å‘Š
        output_path = self.results_dir / "summary_report.json"
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… Summary report saved to: {output_path}")
        
        # æ‰“å°æ€»ç»“
        print("\n" + "="*60)
        print("EVALUATION SUMMARY - v1.1.0")
        print("="*60)
        print(f"Real CAPTCHAs:")
        print(f"  - MAE: {real_results.get('metrics', {}).get('mae', 0):.2f} px")
        print(f"  - 5px Accuracy: {real_results.get('metrics', {}).get('hit_le_5px', 0):.1f}%")
        print(f"\nTest Dataset:")
        print(f"  - MAE: {test_results.get('metrics', {}).get('mae', 0):.2f} px")
        print(f"  - 5px Accuracy: {test_results.get('metrics', {}).get('hit_le_5px', 0):.1f}%")
        print("="*60)
        
        return summary


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Generating v1.1.0 Results Structure")
    print("="*60)
    
    # åˆ›å»ºç”Ÿæˆå™¨
    generator = ResultsGeneratorV110()
    
    # è¯„ä¼°çœŸå®éªŒè¯ç 
    real_results = generator.evaluate_real_captchas()
    
    # è¯„ä¼°æµ‹è¯•æ•°æ®é›†
    test_results = generator.evaluate_test_dataset()
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    if real_results and test_results:
        generator.generate_summary_report(real_results, test_results)
    
    print("\nâœ… All results generated successfully!")
    print(f"ğŸ“ Results location: results/1.1.0/")


if __name__ == "__main__":
    main()