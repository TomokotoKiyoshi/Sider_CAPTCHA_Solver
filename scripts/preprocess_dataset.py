#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
CAPTCHAæ•°æ®é›†é¢„å¤„ç†è„šæœ¬ - æµå¼ç‰ˆæœ¬
ä½¿ç”¨æµå¼å†™å…¥ï¼Œå½»åº•è§£å†³å†…å­˜é—®é¢˜
"""
import sys
import os
from pathlib import Path
import argparse
from datetime import datetime
import psutil
import gc

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(project_root))

# å¯¼å…¥æµå¼æ•°æ®é›†ç”Ÿæˆå™¨
from src.preprocessing.dataset_generator import StreamingDatasetGenerator


def monitor_memory():
    """ç›‘æ§å†…å­˜ä½¿ç”¨"""
    process = psutil.Process()
    mem_info = process.memory_info()
    mem_mb = mem_info.rss / 1024 / 1024
    mem_percent = process.memory_percent()
    return mem_mb, mem_percent


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='CAPTCHA Dataset Preprocessing (Streaming Version)')
    parser.add_argument('--split', type=str, default='train',
                       choices=['train', 'val', 'test', 'all'],
                       help='Dataset split to generate')
    parser.add_argument('--max-samples', type=int, default=None,
                       help='Maximum number of samples to process (for testing)')
    parser.add_argument('--config', type=str, default=None,
                       help='Path to preprocessing config file')
    parser.add_argument('--num-workers', type=int, default=None,
                       help='Number of worker processes')
    parser.add_argument('--batch-size', type=int, default=None,
                       help='Batch size for saving')
    
    args = parser.parse_args()
    
    # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯
    print("=" * 80)
    print("CAPTCHA Dataset Preprocessing (Streaming Version)")
    print("=" * 80)
    print(f"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ˜¾ç¤ºå†…å­˜ä¿¡æ¯
    mem_mb, mem_percent = monitor_memory()
    print(f"Initial memory: {mem_mb:.2f} MB ({mem_percent:.1f}%)")
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šé…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
    if args.config is None:
        config_path = project_root / "config" / "preprocessing_config.yaml"
    else:
        config_path = Path(args.config)
    
    # åŠ è½½é…ç½®æ–‡ä»¶
    import yaml
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # ä»é…ç½®æ–‡ä»¶è¯»å–è·¯å¾„ï¼ˆæ”¯æŒç›¸å¯¹è·¯å¾„ï¼‰
    def resolve_path(path_str):
        path = Path(path_str)
        if not path.is_absolute():
            path = project_root / path
        return path
    
    data_root = resolve_path(config['paths']['data_root'])
    output_dir = resolve_path(config['paths']['output_dir'])
    labels_file = resolve_path(config['paths']['labels_file'])
    
    print(f"\nConfiguration:")
    print(f"  Config file: {config_path}")
    print(f"  Data root: {data_root}")
    print(f"  Output dir: {output_dir}")
    print(f"  Labels file: {labels_file}")
    print(f"  Split: {args.split}")
    
    # æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not labels_file.exists():
        print(f"\nâŒ Error: Labels file not found: {labels_file}")
        print("Please run the captcha generation script first.")
        return 1
    
    print(f"\nOptimizations:")
    print(f"âœ… Streaming write with reusable buffers")
    print(f"âœ… No intermediate lists or accumulation")
    print(f"âœ… Separate file saves (no zip overhead)")
    print(f"âœ… Memory usage is constant and predictable")
    print("=" * 80)
    
    try:
        # åˆ›å»ºæµå¼ç”Ÿæˆå™¨
        generator = StreamingDatasetGenerator(
            data_root=str(data_root),
            output_dir=str(output_dir),
            config_path=str(config_path),
            batch_size=args.batch_size,
            num_workers=args.num_workers
        )
        
        # ç”Ÿæˆæ•°æ®é›†
        if args.split == 'all':
            splits = ['train', 'val', 'test']
        else:
            splits = [args.split]
        
        for split in splits:
            print(f"\nğŸ“ Processing {split} split...")
            
            # æ˜¾ç¤ºå¤„ç†å‰å†…å­˜
            mem_before_mb, mem_before_percent = monitor_memory()
            print(f"Memory before: {mem_before_mb:.2f} MB ({mem_before_percent:.1f}%)")
            
            # ç”Ÿæˆæ•°æ®é›†
            generator.generate_dataset(
                str(labels_file),
                split=split,
                max_samples=args.max_samples
            )
            
            # æ˜¾ç¤ºå¤„ç†åå†…å­˜
            mem_after_mb, mem_after_percent = monitor_memory()
            print(f"Memory after: {mem_after_mb:.2f} MB ({mem_after_percent:.1f}%)")
            print(f"Memory delta: {mem_after_mb - mem_before_mb:+.2f} MB")
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect(2)
        
        # æœ€ç»ˆå†…å­˜ç»Ÿè®¡
        final_mem_mb, final_mem_percent = monitor_memory()
        print(f"\n" + "=" * 80)
        print(f"âœ… All processing completed successfully!")
        print(f"Final memory: {final_mem_mb:.2f} MB ({final_mem_percent:.1f}%)")
        print(f"Total memory growth: {final_mem_mb - mem_mb:+.2f} MB")
        print(f"End time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ Error during preprocessing: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())