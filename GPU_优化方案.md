# GPUåˆ©ç”¨ç‡ä¼˜åŒ–æ–¹æ¡ˆ - CAPTCHA Solver

## é—®é¢˜æè¿°
- **å½“å‰çŠ¶å†µ**ï¼šRTX 5090/4090 GPUåªè·‘åˆ°300Wï¼ˆçº¦52%åˆ©ç”¨ç‡ï¼‰
- **å³°å€¼åŠŸè€—**ï¼š575W
- **ç›®æ ‡**ï¼šæå‡åˆ°450-500Wï¼ˆ80-90%åˆ©ç”¨ç‡ï¼‰

---

## ğŸš¨ å…³é”®é—®é¢˜è¯Šæ–­

### 1. æ··åˆç²¾åº¦é…ç½®é”™è¯¯ã€ä¸¥é‡ã€‘
**é—®é¢˜å®šä½**ï¼š
- é…ç½®æ–‡ä»¶ï¼š`amp: true`ï¼ˆå¸ƒå°”å€¼ï¼‰
- ä»£ç æœŸæœ›ï¼š`amp: 'bf16'`ï¼ˆå­—ç¬¦ä¸²ï¼‰
- æ–‡ä»¶ä½ç½®ï¼š`training_engine.py` L71-80

**å½±å“**ï¼š
- æŸå¤±20-40%æ€§èƒ½
- Tensor Coreæœªè¢«åˆ©ç”¨
- å®é™…è¿è¡Œåœ¨FP32æ¨¡å¼

### 2. torch.compileæœªå¯ç”¨ã€ä¸¥é‡ã€‘
**é—®é¢˜å®šä½**ï¼š
- é…ç½®å­˜åœ¨ä½†æœªè°ƒç”¨
- `compile_model: false`
- `compile_mode: "default"`

**å½±å“**ï¼š
- é”™å¤±10-30%æ€§èƒ½æå‡
- PyTorch 2.0ä¼˜åŒ–æœªç”Ÿæ•ˆ

### 3. ç¡¬ä»¶ä¼˜åŒ–æœªåº”ç”¨ã€é«˜ã€‘
**é—®é¢˜å®šä½**ï¼š
- `apply_hardware_optimizations()`ä»æœªè¢«è°ƒç”¨
- TF32/cuDNNä¼˜åŒ–å¯èƒ½æœªç”Ÿæ•ˆ

### 4. æ¨¡å‹å’Œæ‰¹é‡å¤§å°é—®é¢˜ã€é«˜ã€‘
**ç°çŠ¶**ï¼š
- æ¨¡å‹ï¼š3.5Må‚æ•°ï¼Œ0.45G FLOPs
- batch_sizeï¼š256
- è¾“å…¥ï¼š320Ã—160åƒç´ 
- num_workersï¼š28ï¼ˆè¿‡å¤šï¼‰

**å½±å“**ï¼š
- GPUè®¡ç®—é‡ä¸è¶³
- CPUç“¶é¢ˆ
- å†…å­˜å¸¦å®½æµªè´¹

### 5. è®­ç»ƒå¾ªç¯é¢‘ç¹GPUåŒæ­¥ã€ä¸­ã€‘
**é—®é¢˜**ï¼š
- æ¯ä¸ªbatchéƒ½è°ƒç”¨`.item()`
- ä¸å¿…è¦çš„CPU-GPUåŒæ­¥

---

## âœ… ç«‹å³å®æ–½æ–¹æ¡ˆ

### æ­¥éª¤1ï¼šä¿®å¤æ··åˆç²¾åº¦ï¼ˆ5åˆ†é’Ÿï¼‰

ä¿®æ”¹ `src/training/training_engine.py` L71ï¼š
```python
# åŸä»£ç 
self.use_amp = config['train'].get('amp', 'none') == 'bf16'

# ä¿®æ”¹ä¸º
amp_config = config['train'].get('amp', 'none')
if amp_config == True or amp_config == 'true':
    self.use_amp = True
    self.amp_dtype = torch.bfloat16  # RTX 40ç³»åˆ—ä½¿ç”¨BF16
elif amp_config == 'bf16':
    self.use_amp = True
    self.amp_dtype = torch.bfloat16
else:
    self.use_amp = False
```

### æ­¥éª¤2ï¼šå¯ç”¨torch.compileï¼ˆ5åˆ†é’Ÿï¼‰

åœ¨ `scripts/training/train.py` åˆ›å»ºæ¨¡å‹åæ·»åŠ ï¼š
```python
# åœ¨ L401 åæ·»åŠ 
if config['train'].get('compile_model', False):
    model = torch.compile(model, mode=config['train']['compile_mode'])
    logging.info(f"æ¨¡å‹å·²ç¼–è¯‘ï¼Œæ¨¡å¼ï¼š{config['train']['compile_mode']}")
```

### æ­¥éª¤3ï¼šåº”ç”¨ç¡¬ä»¶ä¼˜åŒ–ï¼ˆ2åˆ†é’Ÿï¼‰

åœ¨ `scripts/training/train.py` L301åæ·»åŠ ï¼š
```python
# åº”ç”¨ç¡¬ä»¶ä¼˜åŒ–
config_manager.apply_hardware_optimizations()
logging.info("ç¡¬ä»¶ä¼˜åŒ–å·²åº”ç”¨")
```

### æ­¥éª¤4ï¼šä¼˜åŒ–é…ç½®æ–‡ä»¶ï¼ˆ2åˆ†é’Ÿï¼‰

ä¿®æ”¹ `config/training_config.yaml`ï¼š
```yaml
train:
  batch_size: 512          # ä»256å¢åŠ åˆ°512ï¼Œåç»­å¯å¢åˆ°1024
  amp: true                # ä¿æŒä¸å˜
  channels_last: true      # ä¿æŒä¸å˜
  num_workers: 8           # ä»28å‡å°‘åˆ°8
  pin_memory: true         # ä¿æŒä¸å˜
  non_blocking: true       # ä¿æŒä¸å˜
  gradient_accumulation_steps: 2  # ä»1å¢åŠ åˆ°2ï¼Œæœ‰æ•ˆbatch=1024
  compile_model: true      # ä»falseæ”¹ä¸ºtrue
  compile_mode: "max-autotune"  # ä»defaultæ”¹ä¸ºmax-autotune
  prefetch_factor: 4       # æ·»åŠ æ­¤é¡¹

optimizer:
  lr: 6.0e-4              # ä»3.0e-4å¢åŠ åˆ°6.0e-4ï¼ˆå› ä¸ºbatchå˜å¤§ï¼‰
```

### æ­¥éª¤5ï¼šå‡å°‘GPUåŒæ­¥ï¼ˆ10åˆ†é’Ÿï¼‰

ä¿®æ”¹ `src/training/training_engine.py`ï¼š
```python
# ä¿®æ”¹ L366-373ï¼Œåªåœ¨éœ€è¦è®°å½•æ—¶è°ƒç”¨.item()
if batch_idx % self.log_interval == 0:
    # è®°å½•æŸå¤±ï¼ˆè½¬æ¢ä¸ºæ ‡é‡ï¼‰
    loss_val = loss.item()
    gap_error_val = gap_error.item()
    slider_error_val = slider_error.item()
    self.batch_metrics['loss'].append(loss_val)
    # ... å…¶ä»–è®°å½•
else:
    # ä¸è®°å½•æ—¶ä¸è°ƒç”¨.item()
    pass
```

### æ­¥éª¤6ï¼šä½¿ç”¨fusedä¼˜åŒ–å™¨ï¼ˆ2åˆ†é’Ÿï¼‰

ä¿®æ”¹ `src/training/training_engine.py` L158ï¼š
```python
# æ·»åŠ  fused=True å‚æ•°
optimizer = AdamW(
    self.model.parameters(),
    lr=lr,
    betas=betas,
    eps=eps,
    weight_decay=weight_decay,
    fused=True  # æ·»åŠ æ­¤è¡Œ
)
```

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

| ä¼˜åŒ–é¡¹ | æ€§èƒ½æå‡ | åŠŸè€—å˜åŒ– | ä¼˜å…ˆçº§ |
|-------|---------|---------|--------|
| ä¿®å¤æ··åˆç²¾åº¦ | +20-40% | 300Wâ†’380W | æœ€é«˜ |
| torch.compile | +10-30% | +50W | é«˜ |
| æ‰¹é‡å¤§å°Ã—2-4 | +30-50% | +80W | é«˜ |
| å‡å°‘åŒæ­¥ | +5-10% | +20W | ä¸­ |
| fusedä¼˜åŒ–å™¨ | +3-5% | +10W | ä½ |
| **æ€»è®¡** | **+68-135%** | **300Wâ†’450-500W** | - |

---

## ğŸ”§ ç›‘æ§è„šæœ¬

åˆ›å»º `scripts/monitor_gpu.py`ï¼š
```python
#!/usr/bin/env python3
"""GPUæ€§èƒ½ç›‘æ§è„šæœ¬"""

import nvidia_ml_py as nvml
import time
import sys

def monitor_gpu():
    nvml.nvmlInit()
    handle = nvml.nvmlDeviceGetHandleByIndex(0)
    
    print("GPUç›‘æ§ä¸­... (Ctrl+Cé€€å‡º)")
    print("-" * 60)
    
    try:
        while True:
            # è·å–åŠŸè€—
            power = nvml.nvmlDeviceGetPowerUsage(handle) / 1000.0
            power_limit = nvml.nvmlDeviceGetPowerManagementLimit(handle) / 1000.0
            
            # è·å–åˆ©ç”¨ç‡
            util = nvml.nvmlDeviceGetUtilizationRates(handle)
            
            # è·å–æ˜¾å­˜
            mem = nvml.nvmlDeviceGetMemoryInfo(handle)
            mem_used_gb = mem.used / 1024 / 1024 / 1024
            mem_total_gb = mem.total / 1024 / 1024 / 1024
            
            # è·å–æ¸©åº¦
            temp = nvml.nvmlDeviceGetTemperature(handle, nvml.NVML_TEMPERATURE_GPU)
            
            # è·å–æ—¶é’Ÿé¢‘ç‡
            sm_clock = nvml.nvmlDeviceGetClockInfo(handle, nvml.NVML_CLOCK_SM)
            mem_clock = nvml.nvmlDeviceGetClockInfo(handle, nvml.NVML_CLOCK_MEM)
            
            # æ‰“å°ä¿¡æ¯
            sys.stdout.write(f"\råŠŸè€—: {power:.1f}W/{power_limit:.0f}W ({power/power_limit*100:.1f}%) | "
                           f"åˆ©ç”¨ç‡: {util.gpu}% | "
                           f"æ˜¾å­˜: {mem_used_gb:.1f}GB/{mem_total_gb:.1f}GB | "
                           f"æ¸©åº¦: {temp}Â°C | "
                           f"æ ¸å¿ƒ: {sm_clock}MHz | "
                           f"æ˜¾å­˜: {mem_clock}MHz")
            sys.stdout.flush()
            
            time.sleep(1)
            
    except KeyboardInterrupt:
        print("\nç›‘æ§å·²åœæ­¢")
        nvml.nvmlShutdown()

if __name__ == "__main__":
    monitor_gpu()
```

---

## ğŸš€ è¿›é˜¶ä¼˜åŒ–æ–¹æ¡ˆï¼ˆå¦‚åŸºç¡€ä¼˜åŒ–ä¸å¤Ÿï¼‰

### 1. ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹
```python
# è€ƒè™‘ä½¿ç”¨ HRNet-W32 æˆ– HRNet-W48
# å‚æ•°é‡ï¼š~30M æˆ– ~65M
# FLOPsï¼š~7G æˆ– ~15G
```

### 2. å¤šGPUè®­ç»ƒï¼ˆDDPï¼‰
```python
# ä½¿ç”¨ torch.distributed è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ
python -m torch.distributed.launch --nproc_per_node=2 train.py
```

### 3. NVIDIA DALIæ•°æ®ç®¡é“
```python
# ä½¿ç”¨DALIæ›¿ä»£PyTorch DataLoader
# GPUç«¯æ•°æ®é¢„å¤„ç†ï¼Œå‡å°‘CPUç“¶é¢ˆ
pip install nvidia-dali-cuda110
```

### 4. å¢åŠ è¾“å…¥åˆ†è¾¨ç‡
```yaml
# è€ƒè™‘ä½¿ç”¨æ›´å¤§çš„è¾“å…¥
input_size: [512, 256]  # ä» [320, 160] å¢åŠ 
```

---

## âš¡ å®æ–½é¡ºåºå»ºè®®

### ç¬¬ä¸€é˜¶æ®µï¼ˆç«‹å³ï¼Œ30åˆ†é’Ÿï¼‰
1. âœ… ä¿®å¤æ··åˆç²¾åº¦é…ç½®
2. âœ… å¯ç”¨torch.compile
3. âœ… è°ƒæ•´batch_sizeå’Œnum_workers
4. âœ… åº”ç”¨ç¡¬ä»¶ä¼˜åŒ–

### ç¬¬äºŒé˜¶æ®µï¼ˆæµ‹è¯•åï¼‰
5. ğŸ“ˆ ç›‘æ§GPUæ€§èƒ½ï¼Œé€æ­¥å¢åŠ batch_size
6. ğŸ“ˆ å¦‚æœæ˜¾å­˜å…è®¸ï¼Œç»§ç»­å¢åŠ åˆ°1024æˆ–2048
7. ğŸ“ˆ è°ƒæ•´gradient_accumulation_steps

### ç¬¬ä¸‰é˜¶æ®µï¼ˆå¯é€‰ï¼‰
8. ğŸ”§ å®æ–½è¿›é˜¶ä¼˜åŒ–æ–¹æ¡ˆ
9. ğŸ”§ è€ƒè™‘æ¨¡å‹æ¶æ„è°ƒæ•´

---

## ğŸ“ æµ‹è¯•éªŒè¯

### è¿è¡Œå‰åŸºå‡†æµ‹è¯•
```bash
# è®°å½•å½“å‰æ€§èƒ½
python scripts/monitor_gpu.py &
python scripts/training/train.py --epochs 1
```

### åº”ç”¨ä¼˜åŒ–åæµ‹è¯•
```bash
# åº”ç”¨æ‰€æœ‰ä¼˜åŒ–å
python scripts/monitor_gpu.py &
python scripts/training/train.py --epochs 1
```

### é¢„æœŸç»“æœ
- **ä¼˜åŒ–å‰**ï¼š~300Wï¼Œ52% GPUåˆ©ç”¨ç‡ï¼Œ~100 samples/s
- **ä¼˜åŒ–å**ï¼š450-500Wï¼Œ80-90% GPUåˆ©ç”¨ç‡ï¼Œ~200-250 samples/s

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **é€æ­¥å¢åŠ batch_size**ï¼šé¿å…OOMé”™è¯¯
2. **ç›‘æ§æ¸©åº¦**ï¼šç¡®ä¿GPUæ¸©åº¦åœ¨å®‰å…¨èŒƒå›´å†…ï¼ˆ<85Â°Cï¼‰
3. **éªŒè¯ç²¾åº¦**ï¼šç¡®ä¿ä¼˜åŒ–ä¸å½±å“æ¨¡å‹æ”¶æ•›
4. **ä¿å­˜é…ç½®å¤‡ä»½**ï¼šåœ¨ä¿®æ”¹å‰å¤‡ä»½åŸé…ç½®æ–‡ä»¶

---

## ğŸ“ æ•…éšœæ’é™¤

### å¦‚æœOOMï¼ˆæ˜¾å­˜ä¸è¶³ï¼‰
- å‡å°batch_size
- å¢åŠ gradient_accumulation_steps
- ä½¿ç”¨gradient checkpointing

### å¦‚æœtorch.compileæŠ¥é”™
- è®¾ç½®`compile_model: false`
- æ£€æŸ¥PyTorchç‰ˆæœ¬ï¼ˆéœ€è¦>=2.0ï¼‰
- å°è¯•ä¸åŒçš„compile_mode

### å¦‚æœæ€§èƒ½æå‡ä¸æ˜æ˜¾
- ç¡®è®¤æ··åˆç²¾åº¦æ˜¯å¦çœŸæ­£å¯ç”¨
- æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–ç“¶é¢ˆï¼ˆå¦‚ç£ç›˜IOï¼‰
- è€ƒè™‘ä½¿ç”¨æ›´å¤§çš„æ¨¡å‹

---

*ç”Ÿæˆæ—¶é—´ï¼š2025-01-16*
*é’ˆå¯¹é¡¹ç›®ï¼šSider_CAPTCHA_Solver v1.1.0*