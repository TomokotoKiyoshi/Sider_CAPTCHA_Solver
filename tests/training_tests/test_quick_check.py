#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæ£€æŸ¥è®­ç»ƒç³»ç»Ÿæ˜¯å¦æ­£å¸¸å·¥ä½œ
"""
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

import torch
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(message)s')


def test_imports():
    """æµ‹è¯•æ‰€æœ‰æ¨¡å—æ˜¯å¦èƒ½æ­£å¸¸å¯¼å…¥"""
    print("\n" + "="*60)
    print("1. æµ‹è¯•æ¨¡å—å¯¼å…¥")
    print("="*60)
    
    try:
        # å¯¼å…¥æ¨¡å‹
        from src.models import create_lite_hrnet_18_fpn
        print("âœ… æ¨¡å‹æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # å¯¼å…¥è®­ç»ƒæ¨¡å—
        from src.training.config_manager import ConfigManager
        print("âœ… é…ç½®ç®¡ç†å™¨å¯¼å…¥æˆåŠŸ")
        
        from src.training.data_pipeline import DataPipeline
        print("âœ… æ•°æ®ç®¡é“å¯¼å…¥æˆåŠŸ")
        
        from src.training.training_engine import TrainingEngine
        print("âœ… è®­ç»ƒå¼•æ“å¯¼å…¥æˆåŠŸ")
        
        from src.training.validator import Validator
        print("âœ… éªŒè¯å™¨å¯¼å…¥æˆåŠŸ")
        
        from src.training.visualizer import Visualizer
        print("âœ… å¯è§†åŒ–å™¨å¯¼å…¥æˆåŠŸ")
        
        # å¯¼å…¥ä¸»è®­ç»ƒè„šæœ¬
        import scripts.training.train as train_module
        print("âœ… ä¸»è®­ç»ƒè„šæœ¬å¯¼å…¥æˆåŠŸ")
        
        return True
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False


def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»ºå’Œå‰å‘ä¼ æ’­"""
    print("\n" + "="*60)
    print("2. æµ‹è¯•æ¨¡å‹åˆ›å»º")
    print("="*60)
    
    try:
        from src.models import create_lite_hrnet_18_fpn
        
        # åˆ›å»ºæ¨¡å‹
        model = create_lite_hrnet_18_fpn()
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # è·å–å‚æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        print(f"   å‚æ•°é‡: {total_params/1e6:.2f}M")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        x = torch.randn(1, 4, 256, 512)
        with torch.no_grad():
            outputs = model(x)
        
        print("âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        print(f"   è¾“å‡ºé”®: {list(outputs.keys())}")
        
        # æµ‹è¯•è§£ç 
        decoded = model.decode_predictions(outputs)
        print("âœ… é¢„æµ‹è§£ç æˆåŠŸ")
        print(f"   è§£ç é”®: {list(decoded.keys())}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_config_loading():
    """æµ‹è¯•é…ç½®æ–‡ä»¶åŠ è½½"""
    print("\n" + "="*60)
    print("3. æµ‹è¯•é…ç½®åŠ è½½")
    print("="*60)
    
    try:
        from src.training.config_manager import ConfigManager
        
        config_path = Path("config/training_config.yaml")
        
        if not config_path.exists():
            print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return False
        
        # åŠ è½½é…ç½®
        config_manager = ConfigManager(str(config_path))
        print("âœ… é…ç½®åŠ è½½æˆåŠŸ")
        
        # æ£€æŸ¥å…³é”®é…ç½®
        config = config_manager.config
        print(f"   æ‰¹æ¬¡å¤§å°: {config['train']['batch_size']}")
        print(f"   å­¦ä¹ ç‡: {config['optimizer']['lr']}")
        print(f"   è®­ç»ƒè½®æ•°: {config['sched']['epochs']}")
        print(f"   æ—©åœé…ç½®: min_epochs={config['eval']['early_stopping']['min_epochs']}, "
              f"patience={config['eval']['early_stopping']['patience']}")
        
        if 'second_guard' in config['eval']['early_stopping']:
            sg = config['eval']['early_stopping']['second_guard']
            print(f"   ç¬¬äºŒé˜²æŠ¤: {sg['metric']} ({sg['mode']}, Î”>{sg['min_delta']})")
        
        return True
        
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return False


def test_device_availability():
    """æµ‹è¯•è®¾å¤‡å¯ç”¨æ€§"""
    print("\n" + "="*60)
    print("4. æµ‹è¯•è®¾å¤‡å¯ç”¨æ€§")
    print("="*60)
    
    # æµ‹è¯•CUDA
    if torch.cuda.is_available():
        print(f"âœ… CUDAå¯ç”¨: {torch.cuda.get_device_name(0)}")
        print(f"   CUDAç‰ˆæœ¬: {torch.version.cuda}")
        print(f"   GPUæ•°é‡: {torch.cuda.device_count()}")
        
        # æµ‹è¯•GPUå†…å­˜
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        print(f"   GPUå†…å­˜: {gpu_memory:.1f}GB")
    else:
        print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
    
    # æµ‹è¯•CPU
    print(f"âœ… CPUæ ¸å¿ƒæ•°: {torch.get_num_threads()}")
    
    return True


def test_data_directory():
    """æµ‹è¯•æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨"""
    print("\n" + "="*60)
    print("5. æµ‹è¯•æ•°æ®ç›®å½•")
    print("="*60)
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶ï¼ˆJSONæ ¼å¼ï¼‰
    train_file = Path("data/split_for_training/train.json")
    val_file = Path("data/split_for_training/val.json")
    test_file = Path("data/split_for_training/test.json")
    processed_dir = Path("data/processed")
    
    results = []
    
    # æ£€æŸ¥è®­ç»ƒæ•°æ®
    if train_file.exists():
        import json
        with open(train_file, 'r', encoding='utf-8') as f:
            train_data = json.load(f)
            if isinstance(train_data, dict) and 'filenames' in train_data:
                num_train = len(train_data['filenames'])
            else:
                num_train = len(train_data)
        print(f"âœ… è®­ç»ƒæ–‡ä»¶å­˜åœ¨: {train_file}")
        print(f"   è®­ç»ƒæ ·æœ¬æ•°: {num_train}")
        results.append(True)
    else:
        print(f"âŒ è®­ç»ƒæ–‡ä»¶ä¸å­˜åœ¨: {train_file}")
        results.append(False)
    
    # æ£€æŸ¥éªŒè¯æ•°æ®
    if val_file.exists():
        with open(val_file, 'r', encoding='utf-8') as f:
            val_data = json.load(f)
            if isinstance(val_data, dict) and 'filenames' in val_data:
                num_val = len(val_data['filenames'])
            else:
                num_val = len(val_data)
        print(f"âœ… éªŒè¯æ–‡ä»¶å­˜åœ¨: {val_file}")
        print(f"   éªŒè¯æ ·æœ¬æ•°: {num_val}")
        results.append(True)
    else:
        print(f"âŒ éªŒè¯æ–‡ä»¶ä¸å­˜åœ¨: {val_file}")
        results.append(False)
    
    # æ£€æŸ¥æµ‹è¯•æ•°æ®
    if test_file.exists():
        with open(test_file, 'r', encoding='utf-8') as f:
            test_data = json.load(f)
            if isinstance(test_data, list):
                num_test = len(test_data)
            elif isinstance(test_data, dict) and 'filenames' in test_data:
                num_test = len(test_data['filenames'])
            else:
                num_test = 0
        print(f"âœ… æµ‹è¯•æ–‡ä»¶å­˜åœ¨: {test_file}")
        print(f"   æµ‹è¯•æ ·æœ¬æ•°: {num_test}")
        results.append(True)
    else:
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        results.append(False)
    
    # æ£€æŸ¥å¤„ç†åçš„å›¾åƒç›®å½•
    if processed_dir.exists():
        num_images = len(list(processed_dir.glob("*.png")))
        print(f"âœ… å›¾åƒç›®å½•å­˜åœ¨: {processed_dir}")
        print(f"   å›¾åƒæ–‡ä»¶æ•°: {num_images}")
        results.append(True)
    else:
        print(f"âŒ å›¾åƒç›®å½•ä¸å­˜åœ¨: {processed_dir}")
        results.append(False)
    
    return all(results)


def test_mini_training():
    """æµ‹è¯•æœ€å°è®­ç»ƒæµç¨‹"""
    print("\n" + "="*60)
    print("6. æµ‹è¯•æœ€å°è®­ç»ƒæµç¨‹")
    print("="*60)
    
    try:
        from src.models import create_lite_hrnet_18_fpn
        import torch.nn as nn
        import torch.optim as optim
        
        # åˆ›å»ºæ¨¡å‹
        model = create_lite_hrnet_18_fpn()
        device = torch.device('cpu')
        model = model.to(device)
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        optimizer = optim.AdamW(model.parameters(), lr=0.001)
        
        # åˆ›å»ºè™šæ‹Ÿæ•°æ®
        batch = {
            'image': torch.randn(2, 4, 256, 512).to(device),
            'gap_coords': torch.randn(2, 2).to(device) * 100 + 160,
            'slider_coords': torch.randn(2, 2).to(device) * 50 + 25
        }
        
        # å‰å‘ä¼ æ’­
        model.train()
        outputs = model(batch['image'])
        print("âœ… å‰å‘ä¼ æ’­æˆåŠŸ")
        
        # ç®€å•æŸå¤±ï¼ˆä»…æµ‹è¯•ï¼‰
        loss = sum(output.mean() for output in outputs.values())
        print(f"âœ… æŸå¤±è®¡ç®—æˆåŠŸ: {loss.item():.4f}")
        
        # åå‘ä¼ æ’­
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        print("âœ… åå‘ä¼ æ’­æˆåŠŸ")
        
        return True
        
    except Exception as e:
        print(f"âŒ æœ€å°è®­ç»ƒæµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "="*60)
    print("è®­ç»ƒç³»ç»Ÿå¿«é€Ÿæ£€æŸ¥")
    print("="*60)
    
    results = []
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    results.append(("æ¨¡å—å¯¼å…¥", test_imports()))
    results.append(("æ¨¡å‹åˆ›å»º", test_model_creation()))
    results.append(("é…ç½®åŠ è½½", test_config_loading()))
    results.append(("è®¾å¤‡å¯ç”¨æ€§", test_device_availability()))
    results.append(("æ•°æ®ç›®å½•", test_data_directory()))
    results.append(("æœ€å°è®­ç»ƒæµç¨‹", test_mini_training()))
    
    # æ‰“å°æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    all_passed = True
    for name, passed in results:
        status = "âœ… é€šè¿‡" if passed else "âŒ å¤±è´¥"
        print(f"{name:15s}: {status}")
        if not passed:
            all_passed = False
    
    print("="*60)
    
    if all_passed:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼è®­ç»ƒç³»ç»Ÿå¯ä»¥æ­£å¸¸å·¥ä½œã€‚")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. ç”Ÿæˆè®­ç»ƒæ•°æ®: python scripts/generate_captchas.py")
        print("2. åˆ’åˆ†æ•°æ®é›†: python scripts/data_generation/split_dataset.py")
        print("3. å¼€å§‹è®­ç»ƒ: python scripts/training/train.py")
    else:
        print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¹¶ä¿®å¤é—®é¢˜ã€‚")
        print("\nå¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:")
        print("1. æ£€æŸ¥æ˜¯å¦å®‰è£…æ‰€æœ‰ä¾èµ–: pip install -r requirements.txt")
        print("2. æ£€æŸ¥æ•°æ®ç›®å½•æ˜¯å¦å­˜åœ¨å¹¶åŒ…å«æ•°æ®")
        print("3. æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨: config/training_config.yaml")
    
    return all_passed


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)