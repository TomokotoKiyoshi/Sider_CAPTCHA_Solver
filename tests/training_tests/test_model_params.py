#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ¨¡å‹å‚æ•°é‡
"""
import sys
from pathlib import Path
project_root = Path(__file__).parent.parent.parent  # ä¸Šç§»ä¸¤çº§åˆ°é¡¹ç›®æ ¹ç›®å½•
sys.path.insert(0, str(project_root))

import torch
from src.models import create_lite_hrnet_18_fpn

def count_parameters(model):
    """è®¡ç®—æ¨¡å‹å‚æ•°é‡"""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    return total_params, trainable_params

def format_params(num_params):
    """æ ¼å¼åŒ–å‚æ•°æ•°é‡"""
    if num_params >= 1e9:
        return f"{num_params/1e9:.2f}B"
    elif num_params >= 1e6:
        return f"{num_params/1e6:.2f}M"
    elif num_params >= 1e3:
        return f"{num_params/1e3:.2f}K"
    else:
        return f"{num_params}"

def analyze_model_layers(model):
    """åˆ†ææ¨¡å‹å„å±‚å‚æ•°åˆ†å¸ƒ"""
    layer_params = {}
    
    for name, module in model.named_modules():
        if len(list(module.children())) == 0:  # å¶å­èŠ‚ç‚¹
            params = sum(p.numel() for p in module.parameters())
            if params > 0:
                # è·å–ä¸»è¦å±‚çº§åç§°
                main_name = name.split('.')[0] if '.' in name else name
                if main_name not in layer_params:
                    layer_params[main_name] = 0
                layer_params[main_name] += params
    
    return layer_params

def main():
    print("=" * 60)
    print("æ¨¡å‹å‚æ•°é‡æµ‹è¯•")
    print("=" * 60)
    
    # åˆ›å»ºæ¨¡å‹
    print("\næ­£åœ¨åˆ›å»ºæ¨¡å‹...")
    model = create_lite_hrnet_18_fpn()
    
    # è®¡ç®—æ€»å‚æ•°é‡
    total_params, trainable_params = count_parameters(model)
    
    print(f"\nğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡:")
    print(f"  æ€»å‚æ•°é‡: {format_params(total_params)} ({total_params:,})")
    print(f"  å¯è®­ç»ƒå‚æ•°: {format_params(trainable_params)} ({trainable_params:,})")
    print(f"  ä¸å¯è®­ç»ƒå‚æ•°: {format_params(total_params - trainable_params)} ({total_params - trainable_params:,})")
    
    # åˆ†æå„å±‚å‚æ•°åˆ†å¸ƒ
    print(f"\nğŸ“ˆ å„æ¨¡å—å‚æ•°åˆ†å¸ƒ:")
    layer_params = analyze_model_layers(model)
    
    # æŒ‰å‚æ•°é‡æ’åº
    sorted_layers = sorted(layer_params.items(), key=lambda x: x[1], reverse=True)
    
    total_counted = sum(layer_params.values())
    for layer_name, params in sorted_layers[:10]:  # æ˜¾ç¤ºå‰10ä¸ªæœ€å¤§çš„å±‚
        percentage = (params / total_params) * 100
        print(f"  {layer_name:20s}: {format_params(params):>10s} ({percentage:5.1f}%)")
    
    # æ¨¡å‹å¤§å°ä¼°ç®—
    print(f"\nğŸ’¾ æ¨¡å‹å­˜å‚¨ä¼°ç®—:")
    model_size_mb = (total_params * 4) / (1024 * 1024)  # å‡è®¾float32
    print(f"  FP32æ¨¡å‹å¤§å°: ~{model_size_mb:.1f} MB")
    print(f"  FP16æ¨¡å‹å¤§å°: ~{model_size_mb/2:.1f} MB")
    print(f"  INT8æ¨¡å‹å¤§å°: ~{model_size_mb/4:.1f} MB")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    print(f"\nğŸ” æµ‹è¯•å‰å‘ä¼ æ’­...")
    try:
        dummy_input = torch.randn(1, 2, 256, 512)  # [B, C, H, W]
        with torch.no_grad():
            output = model(dummy_input)
        
        if isinstance(output, dict):
            print(f"  âœ… å‰å‘ä¼ æ’­æˆåŠŸ!")
            print(f"  è¾“å‡ºé”®: {list(output.keys())}")
            for key, value in output.items():
                if isinstance(value, torch.Tensor):
                    print(f"    {key}: shape={value.shape}")
        else:
            print(f"  âœ… å‰å‘ä¼ æ’­æˆåŠŸ! è¾“å‡ºshape: {output.shape}")
    except Exception as e:
        print(f"  âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
    
    # ä¸ç›®æ ‡å¯¹æ¯”
    print(f"\nğŸ¯ ä¸ç›®æ ‡å¯¹æ¯”:")
    print(f"  å½“å‰: {format_params(total_params)}")
    print(f"  ç›®æ ‡ä¸Šé™: 50M")
    print(f"  ä½¿ç”¨ç‡: {(total_params/50e6)*100:.1f}%")
    
    if total_params > 50e6:
        print(f"  âš ï¸ è­¦å‘Š: è¶…å‡º50Må‚æ•°é™åˆ¶!")
    else:
        print(f"  âœ… ç¬¦åˆå‚æ•°é‡é™åˆ¶ (å‰©ä½™: {format_params(50e6 - total_params)})")
    
    print("\n" + "=" * 60)

if __name__ == "__main__":
    main()