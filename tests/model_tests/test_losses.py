# -*- coding: utf-8 -*-
"""
æŸå¤±å‡½æ•°æµ‹è¯•è„šæœ¬
æµ‹è¯•æ‰€æœ‰æŸå¤±å‡½æ•°çš„è®¡ç®—å’Œæ¢¯åº¦ä¼ æ’­
"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent))

import torch
import torch.nn as nn
from src.models.loss_calculation.focal_loss import FocalLoss, create_focal_loss
from src.models.loss_calculation.offset_loss import OffsetLoss, create_offset_loss
from src.models.loss_calculation.hard_negative_loss import HardNegativeLoss, create_hard_negative_loss
from src.models.loss_calculation.angle_loss import AngleLoss, create_angle_loss
from src.models.loss_calculation.total_loss import TotalLoss, create_total_loss
from src.models.loss_calculation.loss_utils import (
    generate_gaussian_heatmap,
    create_padding_mask,
    coordinate_transform,
    extract_peaks
)


def test_focal_loss():
    """æµ‹è¯•Focal Loss"""
    print("=" * 70)
    print("æµ‹è¯• Focal Loss - CenterNeté£æ ¼çƒ­åŠ›å›¾æŸå¤±")
    print("=" * 70)
    
    batch_size = 2
    height, width = 64, 128
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    focal_loss = FocalLoss(alpha=1.5, beta=4.0, pos_threshold=0.8)  # è°ƒæ•´é˜ˆå€¼ä»¥åŒ¹é…é«˜æ–¯çƒ­å›¾å³°å€¼
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    # é¢„æµ‹ï¼šéšæœºçƒ­åŠ›å›¾ï¼ˆç»è¿‡sigmoidï¼‰ï¼Œéœ€è¦requires_grad
    pred = torch.sigmoid(torch.randn(batch_size, 1, height, width, requires_grad=True))
    
    # ç›®æ ‡ï¼šç”Ÿæˆé«˜æ–¯çƒ­å›¾
    centers = torch.tensor([[30.5, 20.5], [60.5, 40.5]])  # ä¸¤ä¸ªæ‰¹æ¬¡çš„ä¸­å¿ƒç‚¹
    target = generate_gaussian_heatmap(centers, (height, width), sigma=1.5)
    target = target.unsqueeze(1)  # [B, 1, H, W]
    
    # åˆ›å»ºæ©ç 
    mask = torch.ones(batch_size, 1, height, width)
    mask[:, :, :10, :] = 0  # æ¨¡æ‹ŸpaddingåŒºåŸŸ
    
    # è®¡ç®—æŸå¤±
    loss = focal_loss(pred, target, mask)
    
    print(f"\nè¾“å…¥å½¢çŠ¶:")
    print(f"  é¢„æµ‹: {pred.shape}, å€¼åŸŸ: [{pred.min():.4f}, {pred.max():.4f}]")
    print(f"  ç›®æ ‡: {target.shape}, å€¼åŸŸ: [{target.min():.4f}, {target.max():.4f}]")
    print(f"  æ©ç : {mask.shape}")
    
    print(f"\nFocal Losså€¼: {loss.item():.4f}")
    
    # æµ‹è¯•æ¢¯åº¦
    loss.backward()
    print(f"æ¢¯åº¦è®¡ç®—æˆåŠŸ")
    
    # æµ‹è¯•å·¥å‚å‡½æ•°åˆ›å»º
    print("\næµ‹è¯•å·¥å‚å‡½æ•°åˆ›å»º:")
    config = {
        'alpha': 2.0,
        'beta': 4.0,
        'pos_threshold': 0.8
    }
    focal_from_factory = create_focal_loss(config)
    loss_factory = focal_from_factory(pred.detach(), target, mask)
    print(f"å·¥å‚å‡½æ•°åˆ›å»ºçš„Focal Losså€¼: {loss_factory.item():.4f}")
    
    print("\nâœ“ Focal Lossæµ‹è¯•é€šè¿‡")


def test_offset_loss():
    """æµ‹è¯•Offset Loss"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• Offset Loss - å­åƒç´ åç§»æŸå¤±")
    print("=" * 70)
    
    batch_size = 2
    height, width = 64, 128
    num_points = 2  # ç¼ºå£å’Œæ»‘å—
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    offset_loss = OffsetLoss(loss_type='smooth_l1', pos_threshold=0.7)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    # é¢„æµ‹åç§»ï¼š[-0.5, 0.5]èŒƒå›´ï¼Œéœ€è¦requires_grad
    pred_offset = torch.tanh(torch.randn(batch_size, 2*num_points, height, width, requires_grad=True)) * 0.5
    
    # ç›®æ ‡åç§»
    target_offset = torch.randn(batch_size, 2*num_points, height, width) * 0.3
    target_offset = torch.clamp(target_offset, -0.5, 0.5)
    
    # çƒ­åŠ›å›¾ï¼ˆç”¨äºç¡®å®šæ­£æ ·æœ¬ä½ç½®ï¼‰
    centers = torch.tensor([
        [[30, 20], [60, 40]],  # æ‰¹æ¬¡1ï¼šç¼ºå£å’Œæ»‘å—ä¸­å¿ƒ
        [[35, 25], [65, 45]]   # æ‰¹æ¬¡2ï¼šç¼ºå£å’Œæ»‘å—ä¸­å¿ƒ
    ])
    heatmap = torch.zeros(batch_size, num_points, height, width)
    for b in range(batch_size):
        for p in range(num_points):
            x, y = int(centers[b, p, 0]), int(centers[b, p, 1])
            heatmap[b, p, y-2:y+3, x-2:x+3] = 1.0  # ç®€å•çš„æ–¹å½¢åŒºåŸŸ
    
    # è®¡ç®—æŸå¤±
    loss = offset_loss(pred_offset, target_offset, heatmap)
    
    print(f"\nè¾“å…¥å½¢çŠ¶:")
    print(f"  é¢„æµ‹åç§»: {pred_offset.shape}, å€¼åŸŸ: [{pred_offset.min():.4f}, {pred_offset.max():.4f}]")
    print(f"  ç›®æ ‡åç§»: {target_offset.shape}")
    print(f"  çƒ­åŠ›å›¾: {heatmap.shape}")
    
    print(f"\nOffset Losså€¼: {loss.item():.4f}")
    
    # æµ‹è¯•æ¢¯åº¦
    loss.backward()
    print(f"æ¢¯åº¦è®¡ç®—æˆåŠŸ")
    
    print("\nâœ“ Offset Lossæµ‹è¯•é€šè¿‡")


def test_hard_negative_loss():
    """æµ‹è¯•Hard Negative Loss"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• Hard Negative Loss - å‡ç¼ºå£æŠ‘åˆ¶æŸå¤±")
    print("=" * 70)
    
    batch_size = 2
    height, width = 64, 128
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    hn_loss = HardNegativeLoss(margin=0.2, score_type='bilinear')
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    # é¢„æµ‹çš„ç¼ºå£çƒ­åŠ›å›¾ï¼Œéœ€è¦requires_grad
    heatmap = torch.sigmoid(torch.randn(batch_size, 1, height, width, requires_grad=True))
    
    # çœŸå®ç¼ºå£ä¸­å¿ƒï¼ˆæ …æ ¼åæ ‡ï¼‰
    true_centers = torch.tensor([[30.5, 20.5], [60.5, 40.5]])
    
    # å‡ç¼ºå£ä¸­å¿ƒï¼ˆ1-3ä¸ªï¼‰
    fake_centers = [
        torch.tensor([[25.0, 30.0], [55.0, 50.0]]),  # ç¬¬1ä¸ªå‡ç¼ºå£
        torch.tensor([[70.0, 30.0], [40.0, 20.0]]),  # ç¬¬2ä¸ªå‡ç¼ºå£
    ]
    
    # è®¾ç½®çœŸå®ä½ç½®çš„é«˜å“åº”ï¼ˆä½¿ç”¨å…‹éš†é¿å…inplaceæ“ä½œï¼‰
    heatmap_data = heatmap.clone()
    for b in range(batch_size):
        x, y = int(true_centers[b, 0]), int(true_centers[b, 1])
        heatmap_data[b, 0, y, x] = 0.9  # çœŸå®ä½ç½®é«˜å“åº”
    heatmap = heatmap_data
    
    # è®¡ç®—æŸå¤±
    loss = hn_loss(heatmap, true_centers, fake_centers)
    
    print(f"\nè¾“å…¥å½¢çŠ¶:")
    print(f"  çƒ­åŠ›å›¾: {heatmap.shape}")
    print(f"  çœŸå®ä¸­å¿ƒ: {true_centers.shape}")
    print(f"  å‡ç¼ºå£æ•°: {len(fake_centers)}")
    
    print(f"\nHard Negative Losså€¼: {loss.item():.4f}")
    
    # æµ‹è¯•æ¢¯åº¦
    if loss.requires_grad:
        loss.backward()
        print(f"æ¢¯åº¦è®¡ç®—æˆåŠŸ")
    
    print("\nâœ“ Hard Negative Lossæµ‹è¯•é€šè¿‡")


def test_angle_loss():
    """æµ‹è¯•Angle Loss"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• Angle Loss - è§’åº¦æŸå¤±")
    print("=" * 70)
    
    batch_size = 2
    height, width = 64, 128
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    angle_loss = AngleLoss(loss_type='cosine', pos_threshold=0.7)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    # é¢„æµ‹è§’åº¦ï¼ˆsin Î¸, cos Î¸ï¼‰- éœ€è¦å½’ä¸€åŒ–ï¼Œéœ€è¦requires_grad
    pred_angle = torch.randn(batch_size, 2, height, width, requires_grad=True)
    pred_angle = torch.nn.functional.normalize(pred_angle, p=2, dim=1)
    
    # ç›®æ ‡è§’åº¦
    angle_deg = torch.tensor([0.5, -1.0])  # åº¦
    target_angle = AngleLoss.angle_to_sincos(angle_deg)  # è½¬æ¢ä¸ºsin/cos
    target_angle = target_angle.unsqueeze(-1).unsqueeze(-1)  # [B, 2, 1, 1]
    target_angle = target_angle.expand(batch_size, 2, height, width)
    
    # çƒ­åŠ›å›¾ï¼ˆç”¨äºç¡®å®šç›‘ç£åŒºåŸŸï¼‰
    centers = torch.tensor([[30, 20], [60, 40]])
    heatmap = generate_gaussian_heatmap(centers, (height, width), sigma=2.0)
    heatmap = heatmap.unsqueeze(1)  # [B, 1, H, W]
    
    # è®¡ç®—æŸå¤±
    loss = angle_loss(pred_angle, target_angle, heatmap)
    
    print(f"\nè¾“å…¥å½¢çŠ¶:")
    print(f"  é¢„æµ‹è§’åº¦: {pred_angle.shape}")
    print(f"  ç›®æ ‡è§’åº¦: {target_angle.shape}")
    print(f"  çƒ­åŠ›å›¾: {heatmap.shape}")
    
    # éªŒè¯å½’ä¸€åŒ–
    norm = (pred_angle[:, 0:1, :, :] ** 2 + pred_angle[:, 1:2, :, :] ** 2).sqrt()
    print(f"  é¢„æµ‹å½’ä¸€åŒ–éªŒè¯: {norm.mean().item():.6f} (åº”è¯¥â‰ˆ1.0)")
    
    print(f"\nAngle Losså€¼: {loss.item():.4f}")
    
    # æµ‹è¯•æ¢¯åº¦
    loss.backward()
    print(f"æ¢¯åº¦è®¡ç®—æˆåŠŸ")
    
    print("\nâœ“ Angle Lossæµ‹è¯•é€šè¿‡")


def test_total_loss():
    """æµ‹è¯•Total Loss"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• Total Loss - æ€»æŸå¤±å‡½æ•°")
    print("=" * 70)
    
    batch_size = 2
    height, width = 64, 128
    
    # åˆ›å»ºæ€»æŸå¤±å‡½æ•°
    config = {
        'loss_class': 'total',
        'use_angle': True,
        'use_hard_negative': True,
        'loss_weights': {
            'heatmap': 1.0,
            'offset': 1.0,
            'hard_negative': 0.5,
            'angle': 0.5
        }
    }
    total_loss_fn = create_total_loss(config)
    
    # åˆ›å»ºé¢„æµ‹æ•°æ®
    predictions = {
        'heatmap_gap': torch.sigmoid(torch.randn(batch_size, 1, height, width, requires_grad=True)),
        'heatmap_piece': torch.sigmoid(torch.randn(batch_size, 1, height, width, requires_grad=True)),
        'offset': torch.tanh(torch.randn(batch_size, 4, height, width, requires_grad=True)) * 0.5,
        'angle': torch.nn.functional.normalize(
            torch.randn(batch_size, 2, height, width, requires_grad=True), p=2, dim=1
        )
    }
    
    # åˆ›å»ºç›®æ ‡æ•°æ®
    gap_centers = torch.tensor([[30, 20], [35, 25]])
    piece_centers = torch.tensor([[60, 40], [65, 45]])
    
    targets = {
        'heatmap_gap': generate_gaussian_heatmap(gap_centers, (height, width), sigma=1.5).unsqueeze(1),
        'heatmap_piece': generate_gaussian_heatmap(piece_centers, (height, width), sigma=1.5).unsqueeze(1),
        'offset': torch.randn(batch_size, 4, height, width) * 0.3,
        'angle': torch.nn.functional.normalize(
            torch.randn(batch_size, 2, height, width), p=2, dim=1
        ),
        'gap_center': gap_centers,
        'fake_centers': [
            torch.tensor([[25.0, 30.0], [50.0, 35.0]])
        ],
        'mask': torch.ones(batch_size, 1, height, width)
    }
    
    # è®¡ç®—æŸå¤±
    total_loss, loss_dict = total_loss_fn(predictions, targets)
    
    print(f"\næŸå¤±åˆ†è§£:")
    for key, value in loss_dict.items():
        if key != 'total':
            print(f"  {key}: {value.item():.4f}")
    print(f"  " + "-" * 20)
    print(f"  æ€»æŸå¤±: {total_loss.item():.4f}")
    
    # æµ‹è¯•æ¢¯åº¦
    total_loss.backward()
    print(f"\næ¢¯åº¦è®¡ç®—æˆåŠŸ")
    
    # æµ‹è¯•æŸå¤±ç»Ÿè®¡
    print(f"\næŸå¤±ç»Ÿè®¡åŠŸèƒ½:")
    summary = total_loss_fn.get_loss_summary()
    for key, value in summary.items():
        print(f"  {key}: {value:.4f}")
    
    print("\nâœ“ Total Lossæµ‹è¯•é€šè¿‡")


def test_loss_utils():
    """æµ‹è¯•æŸå¤±å·¥å…·å‡½æ•°"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• Loss Utils - æŸå¤±è®¡ç®—å·¥å…·å‡½æ•°")
    print("=" * 70)
    
    # æµ‹è¯•é«˜æ–¯çƒ­å›¾ç”Ÿæˆ
    print("\n1. æµ‹è¯•é«˜æ–¯çƒ­å›¾ç”Ÿæˆ:")
    centers = torch.tensor([[30.5, 20.5], [60.5, 40.5]])
    heatmap = generate_gaussian_heatmap(centers, (64, 128), sigma=1.5)
    print(f"  çƒ­å›¾å½¢çŠ¶: {heatmap.shape}")
    print(f"  å€¼åŸŸ: [{heatmap.min():.4f}, {heatmap.max():.4f}]")
    
    # æµ‹è¯•åæ ‡è½¬æ¢
    print("\n2. æµ‹è¯•åæ ‡è½¬æ¢:")
    coords = torch.tensor([[120.0, 80.0], [240.0, 160.0]])
    grid_coords = coordinate_transform(coords, 'pixel_to_grid', scale=4.0)
    print(f"  åŸå›¾åæ ‡: {coords}")
    print(f"  æ …æ ¼åæ ‡: {grid_coords}")
    
    # æµ‹è¯•å³°å€¼æå–
    print("\n3. æµ‹è¯•å³°å€¼æå–:")
    test_heatmap = torch.zeros(1, 1, 64, 128)
    test_heatmap[0, 0, 20, 30] = 0.9
    test_heatmap[0, 0, 40, 60] = 0.8
    peaks, scores = extract_peaks(test_heatmap, threshold=0.5, nms=True)
    print(f"  å³°å€¼åæ ‡: {peaks[0, 0, :2]}")
    print(f"  å³°å€¼å¾—åˆ†: {scores[0, 0, :2]}")
    
    # æµ‹è¯•paddingæ©ç 
    print("\n4. æµ‹è¯•Paddingæ©ç ç”Ÿæˆ:")
    mask = create_padding_mask((200, 400), (256, 512), downsample=4, pooling='avg')
    print(f"  æ©ç å½¢çŠ¶: {mask.shape}")
    print(f"  æœ‰æ•ˆåŒºåŸŸæ¯”ä¾‹: {mask.mean().item():.2%}")
    
    print("\nâœ“ Loss Utilsæµ‹è¯•é€šè¿‡")


def test_gradient_flow():
    """æµ‹è¯•æ¢¯åº¦æµ"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•æ¢¯åº¦æµ - ç«¯åˆ°ç«¯æ¢¯åº¦ä¼ æ’­")
    print("=" * 70)
    
    # åˆ›å»ºç®€å•æ¨¡å‹
    class SimpleModel(nn.Module):
        def __init__(self):
            super().__init__()
            self.conv = nn.Conv2d(3, 128, 3, padding=1)
            self.head = nn.Conv2d(128, 7, 1)  # 2ä¸ªçƒ­åŠ›å›¾ + 4ä¸ªåç§» + 1ä¸ªæ©ç é€šé“
            
        def forward(self, x):
            feat = self.conv(x)
            out = self.head(feat)
            return {
                'heatmap_gap': torch.sigmoid(out[:, 0:1]),
                'heatmap_piece': torch.sigmoid(out[:, 1:2]),
                'offset': torch.tanh(out[:, 2:6]) * 0.5,
                'mask': torch.sigmoid(out[:, 6:7])
            }
    
    model = SimpleModel()
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    
    # åˆ›å»ºæŸå¤±å‡½æ•°
    loss_fn = TotalLoss(use_angle=False, use_hard_negative=False)
    
    # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
    batch_size = 2
    x = torch.randn(batch_size, 3, 64, 128)
    
    # å‰å‘ä¼ æ’­
    predictions = model(x)
    
    # åˆ›å»ºç›®æ ‡
    targets = {
        'heatmap_gap': torch.rand_like(predictions['heatmap_gap']),
        'heatmap_piece': torch.rand_like(predictions['heatmap_piece']),
        'offset': torch.randn_like(predictions['offset']) * 0.3,
        'mask': predictions['mask'].detach()
    }
    
    # è®¡ç®—æŸå¤±
    loss, loss_dict = loss_fn(predictions, targets)
    
    # åå‘ä¼ æ’­
    optimizer.zero_grad()
    loss.backward()
    
    # æ£€æŸ¥æ¢¯åº¦
    has_grad = True
    for name, param in model.named_parameters():
        if param.grad is None or param.grad.abs().sum() == 0:
            print(f"  è­¦å‘Š: {name} æ²¡æœ‰æ¢¯åº¦")
            has_grad = False
        else:
            print(f"  {name}: æ¢¯åº¦èŒƒæ•° = {param.grad.norm().item():.6f}")
    
    if has_grad:
        print("\nâœ“ æ¢¯åº¦æµæµ‹è¯•é€šè¿‡")
    else:
        print("\nâœ— æ¢¯åº¦æµå­˜åœ¨é—®é¢˜")
    
    # æ›´æ–°å‚æ•°
    optimizer.step()
    print("å‚æ•°æ›´æ–°æˆåŠŸ")


if __name__ == "__main__":
    # æµ‹è¯•å„ä¸ªæŸå¤±å‡½æ•°
    test_focal_loss()
    test_offset_loss()
    test_hard_negative_loss()
    test_angle_loss()
    test_total_loss()
    test_loss_utils()
    test_gradient_flow()
    
    print("\n" + "=" * 70)
    print("ğŸ¯ æ‰€æœ‰æŸå¤±å‡½æ•°æµ‹è¯•é€šè¿‡! âœ“")
    print("æŸå¤±è®¡ç®—æ¨¡å—æ„å»ºå®Œæˆ!")
    print("=" * 70)