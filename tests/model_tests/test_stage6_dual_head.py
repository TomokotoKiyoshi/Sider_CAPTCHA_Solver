# -*- coding: utf-8 -*-
"""
Stage6 åŒå¤´é¢„æµ‹ç½‘ç»œæµ‹è¯•è„šæœ¬
æµ‹è¯•DualHeadçš„é…ç½®åŠ è½½ã€å‰å‘ä¼ æ’­å’Œè¾“å‡ºéªŒè¯
"""
import sys
from pathlib import Path
sys.path.append(str(Path(__file__).parent.parent.parent))

import torch
from src.models.stage6_dual_head import (
    create_stage6_dual_head, DualHead, 
    HeatmapHead, OffsetHead, AngleHead
)
from src.models.config_loader import get_stage6_dual_head_config


def test_stage6_dual_head():
    """æµ‹è¯•Stage6 åŒå¤´é¢„æµ‹ç½‘ç»œ"""
    print("=" * 70)
    print("æµ‹è¯•Stage6 åŒå¤´é¢„æµ‹ç½‘ç»œ - å¯†é›†é¢„æµ‹å¤´")
    print("=" * 70)
    
    # åŠ è½½é…ç½®
    config = get_stage6_dual_head_config()
    print("\né…ç½®ä¿¡æ¯:")
    print(f"  è¾“å…¥é€šé“: {config['in_channels']}")
    print(f"  ä¸­é—´é€šé“: {config['mid_channels']}")
    print(f"  ä½¿ç”¨è§’åº¦: {config['use_angle']}")
    print(f"  ä½¿ç”¨tanhé™åˆ¶åç§»: {config['use_tanh_offset']}")
    
    # åˆ›å»ºæ¨¡å—
    dual_head = create_stage6_dual_head(config)
    dual_head.eval()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥ï¼ˆæ¨¡æ‹ŸStage5 LiteFPNçš„è¾“å‡ºï¼‰
    batch_size = 2
    hf = torch.randn(batch_size, 128, 64, 128)  # [B, 128, 64, 128]
    
    print("\nè¾“å…¥å¼ é‡ï¼ˆæ¥è‡ªStage5 LiteFPNï¼‰:")
    print(f"  Hf (1/4åˆ†è¾¨çŽ‡): {hf.shape}")
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        predictions = dual_head(hf)
    
    print("\nè¾“å‡ºé¢„æµ‹:")
    for key, value in predictions.items():
        print(f"  {key}: {value.shape}")
        if key.startswith('heatmap'):
            print(f"    å€¼åŸŸ: [{value.min().item():.4f}, {value.max().item():.4f}] (æœŸæœ›[0,1])")
        elif key == 'offset':
            print(f"    å€¼åŸŸ: [{value.min().item():.4f}, {value.max().item():.4f}] (æœŸæœ›[-0.5,0.5])")
    
    # éªŒè¯è¾“å‡ºå½¢çŠ¶
    assert predictions['heatmap_gap'].shape == (batch_size, 1, 64, 128), \
        "ç¼ºå£çƒ­åŠ›å›¾å½¢çŠ¶ä¸æ­£ç¡®"
    assert predictions['heatmap_piece'].shape == (batch_size, 1, 64, 128), \
        "æ‹¼å›¾çƒ­åŠ›å›¾å½¢çŠ¶ä¸æ­£ç¡®"
    assert predictions['offset'].shape == (batch_size, 4, 64, 128), \
        "åç§»å›¾å½¢çŠ¶ä¸æ­£ç¡®"
    
    print("\nâœ“ è¾“å‡ºå½¢çŠ¶éªŒè¯é€šè¿‡")
    
    # å‚æ•°ç»Ÿè®¡
    total_params = sum(p.numel() for p in dual_head.parameters())
    trainable_params = sum(p.numel() for p in dual_head.parameters() if p.requires_grad)
    
    print("\nå‚æ•°ç»Ÿè®¡:")
    print(f"  æ€»å‚æ•°é‡: {total_params:,}")
    print(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    print(f"  æ¨¡åž‹å¤§å°: {total_params * 4 / 1024 / 1024:.2f} MB (FP32)")
    
    # åˆ†æ¨¡å—å‚æ•°ç»Ÿè®¡
    heatmap_params = sum(p.numel() for name, p in dual_head.named_parameters() if 'heatmap' in name)
    offset_params = sum(p.numel() for name, p in dual_head.named_parameters() if 'offset' in name)
    
    print("\nåˆ†æ¨¡å—å‚æ•°ç»Ÿè®¡:")
    print(f"  çƒ­åŠ›å›¾å¤´: {heatmap_params:,}")
    print(f"  åç§»å¤´: {offset_params:,}")
    
    print("\nâœ“ Stage6 åŒå¤´é¢„æµ‹ç½‘ç»œæµ‹è¯•å®Œæˆ")
    print("=" * 70)


def test_individual_heads():
    """æµ‹è¯•å„ä¸ªç‹¬ç«‹çš„é¢„æµ‹å¤´"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•ç‹¬ç«‹é¢„æµ‹å¤´")
    print("=" * 70)
    
    batch_size = 2
    in_channels = 128
    height, width = 64, 128
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    x = torch.randn(batch_size, in_channels, height, width)
    
    # æµ‹è¯•çƒ­åŠ›å›¾å¤´
    print("\næµ‹è¯•çƒ­åŠ›å›¾å¤´:")
    heatmap_head = HeatmapHead(in_channels=in_channels)
    heatmap_head.eval()
    
    with torch.no_grad():
        heatmap = heatmap_head(x)
    
    assert heatmap.shape == (batch_size, 1, height, width), \
        "çƒ­åŠ›å›¾å¤´è¾“å‡ºå½¢çŠ¶ä¸æ­£ç¡®"
    assert (heatmap >= 0).all() and (heatmap <= 1).all(), \
        "çƒ­åŠ›å›¾å€¼åŸŸåº”è¯¥åœ¨[0,1]"
    
    print(f"  è¾“å‡ºå½¢çŠ¶: {heatmap.shape}")
    print(f"  å€¼åŸŸ: [{heatmap.min().item():.4f}, {heatmap.max().item():.4f}]")
    print(f"  âœ“ çƒ­åŠ›å›¾å¤´æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•åç§»å¤´
    print("\næµ‹è¯•åç§»å¤´:")
    offset_head = OffsetHead(in_channels=in_channels, use_tanh=True)
    offset_head.eval()
    
    with torch.no_grad():
        offset = offset_head(x)
    
    assert offset.shape == (batch_size, 4, height, width), \
        "åç§»å¤´è¾“å‡ºå½¢çŠ¶ä¸æ­£ç¡®"
    assert (offset >= -0.5).all() and (offset <= 0.5).all(), \
        "åç§»å€¼åŸŸåº”è¯¥åœ¨[-0.5,0.5]"
    
    print(f"  è¾“å‡ºå½¢çŠ¶: {offset.shape}")
    print(f"  å€¼åŸŸ: [{offset.min().item():.4f}, {offset.max().item():.4f}]")
    print(f"  âœ“ åç§»å¤´æµ‹è¯•é€šè¿‡")
    
    # æµ‹è¯•è§’åº¦å¤´
    print("\næµ‹è¯•è§’åº¦å¤´:")
    angle_head = AngleHead(in_channels=in_channels)
    angle_head.eval()
    
    with torch.no_grad():
        angle = angle_head(x)
    
    assert angle.shape == (batch_size, 2, height, width), \
        "è§’åº¦å¤´è¾“å‡ºå½¢çŠ¶ä¸æ­£ç¡®"
    
    # éªŒè¯L2å½’ä¸€åŒ–ï¼šsinÂ²Î¸ + cosÂ²Î¸ = 1
    sin_theta = angle[:, 0:1, :, :]
    cos_theta = angle[:, 1:2, :, :]
    norm = (sin_theta ** 2 + cos_theta ** 2).sqrt()
    
    assert torch.allclose(norm, torch.ones_like(norm), atol=1e-5), \
        "è§’åº¦å¤´è¾“å‡ºæœªæ­£ç¡®å½’ä¸€åŒ–"
    
    print(f"  è¾“å‡ºå½¢çŠ¶: {angle.shape}")
    print(f"  sin Î¸ èŒƒå›´: [{sin_theta.min().item():.4f}, {sin_theta.max().item():.4f}]")
    print(f"  cos Î¸ èŒƒå›´: [{cos_theta.min().item():.4f}, {cos_theta.max().item():.4f}]")
    print(f"  å½’ä¸€åŒ–éªŒè¯: sinÂ²Î¸ + cosÂ²Î¸ â‰ˆ {norm.mean().item():.6f}")
    print(f"  âœ“ è§’åº¦å¤´æµ‹è¯•é€šè¿‡")
    
    print("\n" + "=" * 70)


def test_with_angle():
    """æµ‹è¯•å¸¦è§’åº¦é¢„æµ‹çš„é…ç½®"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•å¸¦è§’åº¦é¢„æµ‹çš„åŒå¤´ç½‘ç»œ")
    print("=" * 70)
    
    # åˆ›å»ºå¸¦è§’åº¦é¢„æµ‹çš„é…ç½®
    config = {
        'in_channels': 128,
        'mid_channels': 64,
        'use_angle': True,  # å¯ç”¨è§’åº¦é¢„æµ‹
        'use_tanh_offset': True
    }
    
    # åˆ›å»ºæ¨¡å—
    dual_head = DualHead(**config)
    dual_head.eval()
    
    # æµ‹è¯•è¾“å…¥
    batch_size = 1
    x = torch.randn(batch_size, 128, 64, 128)
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        predictions = dual_head(x)
    
    print("\nå¯ç”¨è§’åº¦é¢„æµ‹åŽçš„è¾“å‡º:")
    for key, value in predictions.items():
        print(f"  {key}: {value.shape}")
    
    # éªŒè¯è§’åº¦é¢„æµ‹å­˜åœ¨
    assert 'angle' in predictions, "è§’åº¦é¢„æµ‹åº”è¯¥å­˜åœ¨"
    assert predictions['angle'].shape == (batch_size, 2, 64, 128), \
        "è§’åº¦é¢„æµ‹å½¢çŠ¶ä¸æ­£ç¡®"
    
    # éªŒè¯è§’åº¦å½’ä¸€åŒ–
    sin_theta = predictions['angle'][:, 0:1, :, :]
    cos_theta = predictions['angle'][:, 1:2, :, :]
    norm = (sin_theta ** 2 + cos_theta ** 2).sqrt()
    
    print(f"\nè§’åº¦é¢„æµ‹éªŒè¯:")
    print(f"  å½’ä¸€åŒ–: sinÂ²Î¸ + cosÂ²Î¸ â‰ˆ {norm.mean().item():.6f}")
    
    print("\nâœ“ å¸¦è§’åº¦é¢„æµ‹çš„åŒå¤´ç½‘ç»œæµ‹è¯•é€šè¿‡")
    print("=" * 70)


def test_complete_pipeline():
    """æµ‹è¯•å®Œæ•´çš„æ•°æ®æµï¼ˆStage5 â†’ Stage6ï¼‰"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•å®Œæ•´æ•°æ®æµï¼ˆStage5 LiteFPN â†’ Stage6 DualHeadï¼‰")
    print("=" * 70)
    
    # å¯¼å…¥Stage5
    from src.models.stage5_lite_fpn import create_stage5_lite_fpn
    from src.models.config_loader import get_stage5_lite_fpn_config
    
    # åˆ›å»ºStage4è¾“å‡ºï¼ˆæ¨¡æ‹Ÿï¼‰
    batch_size = 2
    stage4_output = [
        torch.randn(batch_size, 32, 64, 128),   # B1
        torch.randn(batch_size, 64, 32, 64),    # B2
        torch.randn(batch_size, 128, 16, 32),   # B3
        torch.randn(batch_size, 256, 8, 16),    # B4
    ]
    
    print("Stage4è¾“å‡º:")
    for i, feat in enumerate(stage4_output, 1):
        print(f"  B{i}: {feat.shape}")
    
    # Stage5 LiteFPNå¤„ç†
    stage5_config = get_stage5_lite_fpn_config()
    stage5 = create_stage5_lite_fpn(stage5_config)
    stage5.eval()
    
    with torch.no_grad():
        hf = stage5(stage4_output)
    
    print("\nStage5 LiteFPNè¾“å‡º:")
    print(f"  Hf: {hf.shape} (1/4åˆ†è¾¨çŽ‡ä¸»ç‰¹å¾)")
    
    # Stage6 DualHeadå¤„ç†
    stage6_config = get_stage6_dual_head_config()
    stage6 = create_stage6_dual_head(stage6_config)
    stage6.eval()
    
    with torch.no_grad():
        predictions = stage6(hf)
    
    print("\nStage6 DualHeadè¾“å‡º:")
    for key, value in predictions.items():
        print(f"  {key}: {value.shape}")
    
    # éªŒè¯ç«¯åˆ°ç«¯è¾“å‡º
    assert predictions['heatmap_gap'].shape == (batch_size, 1, 64, 128), \
        "ç«¯åˆ°ç«¯ç¼ºå£çƒ­åŠ›å›¾å½¢çŠ¶ä¸æ­£ç¡®"
    assert predictions['heatmap_piece'].shape == (batch_size, 1, 64, 128), \
        "ç«¯åˆ°ç«¯æ‹¼å›¾çƒ­åŠ›å›¾å½¢çŠ¶ä¸æ­£ç¡®"
    assert predictions['offset'].shape == (batch_size, 4, 64, 128), \
        "ç«¯åˆ°ç«¯åç§»å›¾å½¢çŠ¶ä¸æ­£ç¡®"
    
    print("\nâœ“ å®Œæ•´æ•°æ®æµæµ‹è¯•é€šè¿‡")
    print("=" * 70)


def test_decode_coordinates():
    """æµ‹è¯•åæ ‡è§£ç é€»è¾‘"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•åæ ‡è§£ç ")
    print("=" * 70)
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„é¢„æµ‹è¾“å‡º
    batch_size = 1
    height, width = 64, 128  # 1/4åˆ†è¾¨çŽ‡
    
    # åˆ›å»ºçƒ­åŠ›å›¾ï¼Œåœ¨ç‰¹å®šä½ç½®è®¾ç½®å³°å€¼
    heatmap = torch.zeros(batch_size, 1, height, width)
    gap_y, gap_x = 30, 60  # æ …æ ¼åæ ‡
    piece_y, piece_x = 35, 20  # æ …æ ¼åæ ‡
    
    heatmap[0, 0, gap_y, gap_x] = 1.0  # ç¼ºå£å³°å€¼
    
    # åˆ›å»ºåç§»å›¾
    offset = torch.zeros(batch_size, 4, height, width)
    offset[0, 0, gap_y, gap_x] = 0.3   # du_gap
    offset[0, 1, gap_y, gap_x] = -0.2  # dv_gap
    offset[0, 2, piece_y, piece_x] = -0.1  # du_piece
    offset[0, 3, piece_y, piece_x] = 0.4   # dv_piece
    
    print("æ¨¡æ‹Ÿé¢„æµ‹:")
    print(f"  ç¼ºå£æ …æ ¼åæ ‡: ({gap_x}, {gap_y})")
    print(f"  ç¼ºå£å­åƒç´ åç§»: (0.3, -0.2)")
    print(f"  æ‹¼å›¾æ …æ ¼åæ ‡: ({piece_x}, {piece_y})")
    print(f"  æ‹¼å›¾å­åƒç´ åç§»: (-0.1, 0.4)")
    
    # è§£ç åæ ‡ï¼ˆç®€åŒ–ç‰ˆï¼‰
    downsample = 4  # ä¸‹é‡‡æ ·çŽ‡
    
    # ç¼ºå£åæ ‡
    gap_x_final = (gap_x + 0.3) * downsample
    gap_y_final = (gap_y - 0.2) * downsample
    
    # æ‹¼å›¾åæ ‡
    piece_x_final = (piece_x - 0.1) * downsample
    piece_y_final = (piece_y + 0.4) * downsample
    
    print("\nè§£ç åŽçš„åŽŸå›¾åæ ‡:")
    print(f"  ç¼ºå£: ({gap_x_final:.1f}, {gap_y_final:.1f})")
    print(f"  æ‹¼å›¾: ({piece_x_final:.1f}, {piece_y_final:.1f})")
    
    print("\nåæ ‡æ˜ å°„å…¬å¼:")
    print("  åŽŸå›¾åæ ‡ = (æ …æ ¼åæ ‡ + å­åƒç´ åç§») Ã— ä¸‹é‡‡æ ·çŽ‡")
    print("  ä¸‹é‡‡æ ·çŽ‡ = 4 (ä»Ž256Ã—512åˆ°64Ã—128)")
    
    print("\nâœ“ åæ ‡è§£ç æµ‹è¯•å®Œæˆ")
    print("=" * 70)


if __name__ == "__main__":
    # æµ‹è¯•Stage6ä¸»æ¨¡å—
    test_stage6_dual_head()
    
    # æµ‹è¯•ç‹¬ç«‹é¢„æµ‹å¤´
    test_individual_heads()
    
    # æµ‹è¯•å¸¦è§’åº¦é¢„æµ‹çš„é…ç½®
    test_with_angle()
    
    # æµ‹è¯•å®Œæ•´ç®¡é“
    test_complete_pipeline()
    
    # æµ‹è¯•åæ ‡è§£ç 
    test_decode_coordinates()
    
    print("\n" + "=" * 70)
    print("ðŸŽ¯ æ‰€æœ‰Stage6 åŒå¤´é¢„æµ‹ç½‘ç»œæµ‹è¯•é€šè¿‡! âœ“")
    print("å¯†é›†é¢„æµ‹å¤´æž„å»ºå®Œæˆ!")
    print("=" * 70)