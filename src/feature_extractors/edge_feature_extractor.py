# -*- coding: utf-8 -*-
"""
è¾¹ç¼˜ç‰¹å¾æå–å™¨ - ç”¨äºæå–éªŒè¯ç çš„è¾¹ç¼˜å’Œå½¢çŠ¶ç‰¹å¾
è§£å†³Domain Gapé—®é¢˜çš„å…³é”®ç»„ä»¶
"""
import cv2
import numpy as np
from typing import Dict, List, Tuple, Optional
from pathlib import Path
import matplotlib.pyplot as plt
from tqdm import tqdm


class EdgeFeatureExtractor:
    """è¾¹ç¼˜ç‰¹å¾æå–å™¨"""
    
    def __init__(self, puzzle_size: int = 40):
        """
        åˆå§‹åŒ–è¾¹ç¼˜ç‰¹å¾æå–å™¨
        
        Args:
            puzzle_size: æ‹¼å›¾å—çš„å¤§å°ï¼ˆåƒç´ ï¼‰
        """
        self.puzzle_size = puzzle_size
        self.templates = None
        self._generate_puzzle_templates()
    
    def _generate_puzzle_templates(self):
        """ç”Ÿæˆæ‹¼å›¾å½¢çŠ¶æ¨¡æ¿"""
        self.templates = []
        size = self.puzzle_size
        
        # ç”Ÿæˆå‡ ç§å¸¸è§çš„æ‹¼å›¾å½¢çŠ¶
        templates_specs = [
            # æ ‡å‡†æ‹¼å›¾å—ï¼ˆå‡¸èµ·åœ¨å³ä¾§ï¼‰
            {'name': 'standard_right', 'type': 'convex_right'},
            # æ ‡å‡†æ‹¼å›¾å—ï¼ˆå‡¸èµ·åœ¨å·¦ä¾§ï¼‰
            {'name': 'standard_left', 'type': 'convex_left'},
            # åœ†å½¢ç¼ºå£
            {'name': 'circle', 'type': 'circle'},
            # æ–¹å½¢ç¼ºå£
            {'name': 'square', 'type': 'square'},
        ]
        
        for spec in templates_specs:
            template = self._create_puzzle_template(size, spec['type'])
            self.templates.append({
                'name': spec['name'],
                'template': template,
                'edges': cv2.Canny(template, 50, 150)
            })
    
    def _create_puzzle_template(self, size: int, shape_type: str) -> np.ndarray:
        """
        åˆ›å»ºå•ä¸ªæ‹¼å›¾æ¨¡æ¿
        
        Args:
            size: æ¨¡æ¿å¤§å°
            shape_type: å½¢çŠ¶ç±»å‹
            
        Returns:
            æ¨¡æ¿å›¾åƒï¼ˆäºŒå€¼å›¾ï¼‰
        """
        template = np.zeros((size, size), dtype=np.uint8)
        
        if shape_type == 'convex_right':
            # åˆ›å»ºå³ä¾§æœ‰å‡¸èµ·çš„æ‹¼å›¾å½¢çŠ¶
            template[:, :size//2] = 255
            cv2.circle(template, (size//2, size//2), size//4, 255, -1)
            
        elif shape_type == 'convex_left':
            # åˆ›å»ºå·¦ä¾§æœ‰å‡¸èµ·çš„æ‹¼å›¾å½¢çŠ¶
            template[:, size//2:] = 255
            cv2.circle(template, (size//2, size//2), size//4, 255, -1)
            
        elif shape_type == 'circle':
            # åœ†å½¢
            cv2.circle(template, (size//2, size//2), size//3, 255, -1)
            
        elif shape_type == 'square':
            # æ–¹å½¢
            margin = size // 5
            template[margin:-margin, margin:-margin] = 255
        
        return template
    
    def load_puzzle_templates(self) -> List[Dict]:
        """
        åŠ è½½æ‹¼å›¾æ¨¡æ¿
        
        Returns:
            æ¨¡æ¿åˆ—è¡¨
        """
        if self.templates is None:
            self._generate_puzzle_templates()
        return self.templates
    
    def match_templates(self, edge_image: np.ndarray, templates: List[Dict]) -> np.ndarray:
        """
        åœ¨è¾¹ç¼˜å›¾åƒä¸­åŒ¹é…æ‹¼å›¾æ¨¡æ¿
        
        Args:
            edge_image: è¾¹ç¼˜æ£€æµ‹åçš„å›¾åƒ
            templates: æ¨¡æ¿åˆ—è¡¨
            
        Returns:
            æ¨¡æ¿åŒ¹é…å“åº”å›¾
        """
        h, w = edge_image.shape
        response_map = np.zeros((h, w), dtype=np.float32)
        
        for template_info in templates:
            template = template_info['edges']
            
            # ä½¿ç”¨æ¨¡æ¿åŒ¹é…
            result = cv2.matchTemplate(edge_image, template, cv2.TM_CCOEFF_NORMED)
            
            # å°†ç»“æœå¡«å……åˆ°åŸå§‹å¤§å°
            th, tw = template.shape
            padded_result = np.zeros((h, w), dtype=np.float32)
            padded_result[:result.shape[0], :result.shape[1]] = np.abs(result)
            
            # å–æœ€å¤§å“åº”
            response_map = np.maximum(response_map, padded_result)
        
        return response_map
    
    def extract_features(self, image: np.ndarray) -> Dict[str, np.ndarray]:
        """
        æå–å›¾åƒçš„è¾¹ç¼˜ç‰¹å¾
        
        Args:
            image: è¾“å…¥å›¾åƒï¼ˆBGRæˆ–RGBæ ¼å¼ï¼‰
            
        Returns:
            ç‰¹å¾å­—å…¸ï¼ŒåŒ…å«ï¼š
            - edges: Cannyè¾¹ç¼˜
            - gradient: Sobelæ¢¯åº¦å¹…å€¼
            - morph: å½¢æ€å­¦æ¢¯åº¦
            - template: æ¨¡æ¿åŒ¹é…å“åº”
        """
        # è½¬æ¢ä¸ºç°åº¦å›¾
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # 1. Cannyè¾¹ç¼˜æ£€æµ‹
        edges_canny = cv2.Canny(gray, 50, 150)
        
        # 2. Sobelæ¢¯åº¦
        sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
        gradient_magnitude = np.clip(gradient_magnitude, 0, 255).astype(np.uint8)
        
        # 3. å½¢æ€å­¦æ¢¯åº¦
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        morph_gradient = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)
        
        # 4. æ‹¼å›¾å½¢çŠ¶æ¨¡æ¿åŒ¹é…
        puzzle_templates = self.load_puzzle_templates()
        template_response = self.match_templates(edges_canny, puzzle_templates)
        template_response = (template_response * 255).astype(np.uint8)
        
        return {
            'edges': edges_canny,
            'gradient': gradient_magnitude,
            'morph': morph_gradient,
            'template': template_response
        }
    
    def visualize_features(self, image: np.ndarray, features: Dict[str, np.ndarray], 
                          save_path: Optional[str] = None, show: bool = False):
        """
        å¯è§†åŒ–æå–çš„ç‰¹å¾
        
        Args:
            image: åŸå§‹å›¾åƒ
            features: ç‰¹å¾å­—å…¸
            save_path: ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            show: æ˜¯å¦æ˜¾ç¤ºå›¾åƒ
        """
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        
        # åŸå§‹å›¾åƒ
        axes[0, 0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
        axes[0, 0].set_title('Original Image')
        axes[0, 0].axis('off')
        
        # Cannyè¾¹ç¼˜
        axes[0, 1].imshow(features['edges'], cmap='gray')
        axes[0, 1].set_title('Canny Edges')
        axes[0, 1].axis('off')
        
        # Sobelæ¢¯åº¦
        axes[0, 2].imshow(features['gradient'], cmap='gray')
        axes[0, 2].set_title('Sobel Gradient Magnitude')
        axes[0, 2].axis('off')
        
        # å½¢æ€å­¦æ¢¯åº¦
        axes[1, 0].imshow(features['morph'], cmap='gray')
        axes[1, 0].set_title('Morphological Gradient')
        axes[1, 0].axis('off')
        
        # æ¨¡æ¿åŒ¹é…å“åº”
        axes[1, 1].imshow(features['template'], cmap='hot')
        axes[1, 1].set_title('Template Matching Response')
        axes[1, 1].axis('off')
        
        # ç»„åˆç‰¹å¾ï¼ˆåŠ æƒå¹³å‡ï¼‰
        combined = (
            0.3 * features['edges'] + 
            0.3 * features['gradient'] + 
            0.2 * features['morph'] + 
            0.2 * features['template']
        ).astype(np.uint8)
        axes[1, 2].imshow(combined, cmap='gray')
        axes[1, 2].set_title('Combined Features')
        axes[1, 2].axis('off')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=100, bbox_inches='tight')
        
        if show:
            plt.show()
        else:
            plt.close()


def batch_process():
    """æ‰¹é‡å¤„ç†éªŒè¯ç å›¾åƒçš„è¾¹ç¼˜ç‰¹å¾"""
    print("è¾¹ç¼˜ç‰¹å¾æ‰¹é‡æå–")
    print("=" * 50)
    
    # åˆ›å»ºç‰¹å¾æå–å™¨
    extractor = EdgeFeatureExtractor(puzzle_size=40)
    
    # è¾“å‡ºæ ¹ç›®å½•
    output_root = Path("D:/Hacker/Sider_CAPTCHA_Solver/extracted_features")
    
    # ä¸ºåˆæˆå›¾å’ŒçœŸå®å›¾ç‰‡åˆ›å»ºç‹¬ç«‹çš„è¾“å‡ºç›®å½•
    synthetic_output = output_root / "synthetic_captchas"
    real_output = output_root / "real_captchas"
    comparison_output = output_root / "comparisons"
    
    # åˆ›å»ºæ‰€æœ‰å¿…è¦çš„ç›®å½•
    synthetic_output.mkdir(parents=True, exist_ok=True)
    real_output.mkdir(parents=True, exist_ok=True)
    comparison_output.mkdir(parents=True, exist_ok=True)
    
    # æ”¶é›†å›¾åƒæ–‡ä»¶
    all_images = []
    
    # ä»data/captchasè¯»å–ä¸åŒåŸå§‹å›¾ç‰‡çš„éªŒè¯ç 
    captchas_dir = Path("data/captchas")
    if captchas_dir.exists():
        # è·å–æ‰€æœ‰éªŒè¯ç æ–‡ä»¶
        all_captcha_files = sorted(captchas_dir.glob("*.png"))
        
        # æå–ä¸åŒçš„åŸå§‹å›¾ç‰‡ç¼–å·ï¼ˆPicXXXXï¼‰
        pic_groups = {}
        for f in all_captcha_files:
            # ä»æ–‡ä»¶åæå–Picç¼–å·
            pic_id = f.stem.split('_')[0]  # è·å– PicXXXX éƒ¨åˆ†
            if pic_id not in pic_groups:
                pic_groups[pic_id] = []
            pic_groups[pic_id].append(f)
        
        # ä»æ¯ä¸ªä¸åŒçš„Picç»„ä¸­é€‰æ‹©ä¸€ä¸ªéªŒè¯ç ï¼Œæœ€å¤š50ä¸ª
        captcha_files = []
        for pic_id in sorted(pic_groups.keys())[:50]:
            # ä»æ¯ä¸ªPicç»„ä¸­é€‰æ‹©ç¬¬ä¸€ä¸ªéªŒè¯ç 
            captcha_files.append(pic_groups[pic_id][0])
        
        all_images.extend([(f, 'synthetic') for f in captcha_files])
        print(f"æ‰¾åˆ° {len(pic_groups)} ä¸ªä¸åŒçš„åŸå§‹å›¾ç‰‡")
        print(f"é€‰æ‹©äº† {len(captcha_files)} å¼ åˆæˆéªŒè¯ç ï¼ˆæ¯ä¸ªåŸå§‹å›¾ç‰‡é€‰ä¸€å¼ ï¼‰")
    
    # ä»data/real_captchas/annotatedè¯»å–ä¸åŒåŸå§‹å›¾ç‰‡çš„çœŸå®éªŒè¯ç 
    real_dir = Path("data/real_captchas/annotated")
    if real_dir.exists():
        # è·å–æ‰€æœ‰çœŸå®éªŒè¯ç æ–‡ä»¶
        all_real_files = sorted(real_dir.glob("*.png"))
        
        # æå–ä¸åŒçš„åŸå§‹å›¾ç‰‡ç¼–å·ï¼ˆPicXXXXï¼‰
        real_pic_groups = {}
        for f in all_real_files:
            # ä»æ–‡ä»¶åæå–Picç¼–å·
            pic_id = f.stem.split('_')[0]  # è·å– PicXXXX éƒ¨åˆ†
            if pic_id not in real_pic_groups:
                real_pic_groups[pic_id] = []
            real_pic_groups[pic_id].append(f)
        
        # ä»æ¯ä¸ªä¸åŒçš„Picç»„ä¸­é€‰æ‹©ä¸€ä¸ªéªŒè¯ç ï¼Œæœ€å¤š50ä¸ª
        real_files = []
        for pic_id in sorted(real_pic_groups.keys())[:50]:
            # ä»æ¯ä¸ªPicç»„ä¸­é€‰æ‹©ç¬¬ä¸€ä¸ªéªŒè¯ç 
            real_files.append(real_pic_groups[pic_id][0])
        
        all_images.extend([(f, 'real') for f in real_files])
        print(f"æ‰¾åˆ° {len(real_pic_groups)} ä¸ªä¸åŒçš„çœŸå®åŸå§‹å›¾ç‰‡")
        print(f"é€‰æ‹©äº† {len(real_files)} å¼ çœŸå®éªŒè¯ç ï¼ˆæ¯ä¸ªåŸå§‹å›¾ç‰‡é€‰ä¸€å¼ ï¼‰")
    
    if not all_images:
        print("æœªæ‰¾åˆ°ä»»ä½•å›¾åƒæ–‡ä»¶ï¼")
        return
    
    print(f"\næ€»å…±å¤„ç† {len(all_images)} å¼ å›¾åƒ")
    print(f"è¾“å‡ºæ ¹ç›®å½•: {output_root}")
    print(f"  - åˆæˆå›¾ç‰‡ç‰¹å¾: {synthetic_output}")
    print(f"  - çœŸå®å›¾ç‰‡ç‰¹å¾: {real_output}")
    print(f"  - å¯¹æ¯”åˆ†æ: {comparison_output}")
    
    # åˆ†åˆ«å¤„ç†åˆæˆå›¾å’ŒçœŸå®å›¾ç‰‡
    synthetic_count = 0
    real_count = 0
    
    for idx, (image_path, image_type) in enumerate(tqdm(all_images, desc="Processing")):
        try:
            # è¯»å–å›¾åƒ
            image = cv2.imread(str(image_path))
            if image is None:
                print(f"æ— æ³•è¯»å–: {image_path.name}")
                continue
            
            # æå–ç‰¹å¾
            features = extractor.extract_features(image)
            
            # æ ¹æ®ç±»å‹é€‰æ‹©è¾“å‡ºç›®å½•
            if image_type == 'synthetic':
                save_name = f"synthetic_{synthetic_count:04d}_{image_path.stem}_features.png"
                save_path = synthetic_output / save_name
                synthetic_count += 1
            else:  # real
                save_name = f"real_{real_count:04d}_{image_path.stem}_features.png"
                save_path = real_output / save_name
                real_count += 1
            
            # ä¿å­˜å¯è§†åŒ–
            extractor.visualize_features(image, features, str(save_path), show=False)
            
        except Exception as e:
            print(f"å¤„ç† {image_path.name} æ—¶å‡ºé”™: {e}")
            continue
    
    print(f"\nâœ… æ‰¹é‡å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“ åˆæˆå›¾ç‰‡: å¤„ç†äº† {synthetic_count} å¼ ")
    print(f"ğŸ“ çœŸå®å›¾ç‰‡: å¤„ç†äº† {real_count} å¼ ")
    
    # ç”Ÿæˆå¯¹æ¯”ç¤ºä¾‹ï¼ˆå‰5ä¸ªåˆæˆ vs å‰5ä¸ªçœŸå®ï¼‰
    print("\nç”Ÿæˆå¯¹æ¯”ç¤ºä¾‹...")
    fig, axes = plt.subplots(5, 4, figsize=(16, 20))
    
    synthetic_samples = [img for img, t in all_images if t == 'synthetic'][:5]
    real_samples = [img for img, t in all_images if t == 'real'][:5]
    
    for i in range(min(5, len(synthetic_samples))):
        # åˆæˆæ•°æ®
        syn_img = cv2.imread(str(synthetic_samples[i]))
        syn_features = extractor.extract_features(syn_img)
        
        axes[i, 0].imshow(cv2.cvtColor(syn_img, cv2.COLOR_BGR2RGB))
        axes[i, 0].set_title(f'Synthetic #{i+1}')
        axes[i, 0].axis('off')
        
        axes[i, 1].imshow(syn_features['edges'], cmap='gray')
        axes[i, 1].set_title('Edges')
        axes[i, 1].axis('off')
    
    for i in range(min(5, len(real_samples))):
        # çœŸå®æ•°æ®
        real_img = cv2.imread(str(real_samples[i]))
        real_features = extractor.extract_features(real_img)
        
        axes[i, 2].imshow(cv2.cvtColor(real_img, cv2.COLOR_BGR2RGB))
        axes[i, 2].set_title(f'Real #{i+1}')
        axes[i, 2].axis('off')
        
        axes[i, 3].imshow(real_features['edges'], cmap='gray')
        axes[i, 3].set_title('Edges')
        axes[i, 3].axis('off')
    
    plt.suptitle('Synthetic vs Real CAPTCHA Edge Features', fontsize=16)
    plt.tight_layout()
    comparison_path = comparison_output / "synthetic_vs_real_edge_comparison.png"
    plt.savefig(comparison_path, dpi=120, bbox_inches='tight')
    plt.close()
    
    print(f"ğŸ“Š å¯¹æ¯”å›¾ä¿å­˜åœ¨: {comparison_path}")
    
    # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    print("\nç”Ÿæˆç‰¹å¾ç»Ÿè®¡æŠ¥å‘Š...")
    generate_feature_statistics(synthetic_samples[:10], real_samples[:10], extractor, comparison_output)


def generate_feature_statistics(synthetic_samples, real_samples, extractor, output_dir):
    """ç”Ÿæˆç‰¹å¾ç»Ÿè®¡æŠ¥å‘Š"""
    import json
    
    # è®¡ç®—åˆæˆå›¾å’ŒçœŸå®å›¾çš„è¾¹ç¼˜å¯†åº¦ç»Ÿè®¡
    synthetic_edge_densities = []
    real_edge_densities = []
    
    for img_path in synthetic_samples:
        img = cv2.imread(str(img_path))
        if img is not None:
            features = extractor.extract_features(img)
            edge_density = np.sum(features['edges'] > 0) / features['edges'].size
            synthetic_edge_densities.append(edge_density)
    
    for img_path in real_samples:
        img = cv2.imread(str(img_path))
        if img is not None:
            features = extractor.extract_features(img)
            edge_density = np.sum(features['edges'] > 0) / features['edges'].size
            real_edge_densities.append(edge_density)
    
    # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
    stats = {
        "synthetic_captchas": {
            "samples_analyzed": len(synthetic_edge_densities),
            "edge_density": {
                "mean": float(np.mean(synthetic_edge_densities)),
                "std": float(np.std(synthetic_edge_densities)),
                "min": float(np.min(synthetic_edge_densities)),
                "max": float(np.max(synthetic_edge_densities))
            }
        },
        "real_captchas": {
            "samples_analyzed": len(real_edge_densities),
            "edge_density": {
                "mean": float(np.mean(real_edge_densities)),
                "std": float(np.std(real_edge_densities)),
                "min": float(np.min(real_edge_densities)),
                "max": float(np.max(real_edge_densities))
            }
        },
        "comparison": {
            "edge_density_diff": float(np.mean(real_edge_densities) - np.mean(synthetic_edge_densities)),
            "analysis": "çœŸå®éªŒè¯ç çš„è¾¹ç¼˜å¯†åº¦é€šå¸¸æ›´é«˜ï¼Œè¡¨æ˜çº¹ç†æ›´å¤æ‚" if np.mean(real_edge_densities) > np.mean(synthetic_edge_densities) else "åˆæˆéªŒè¯ç çš„è¾¹ç¼˜å¯†åº¦æ›´é«˜"
        }
    }
    
    # ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š
    stats_path = output_dir / "feature_statistics.json"
    with open(stats_path, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“ˆ ç»Ÿè®¡æŠ¥å‘Šä¿å­˜åœ¨: {stats_path}")


if __name__ == "__main__":
    batch_process()